<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.2">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.loli.net/css?family=consolas:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/themes/blue/pace-theme-minimal.css">
  <script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js" integrity="sha256-gqd7YTjg/BtfqWSwsJOvndl0Bxc8gFImLEkXQT8+qj0=" crossorigin="anonymous"></script>

<script class="next-config" data-name="main" type="application/json">{"hostname":"example.com","root":"/","images":"/images","scheme":"Muse","darkmode":false,"version":"8.8.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":false,"bookmark":{"enable":true,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":"disqus","storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>
<meta name="description" content="Be smart! Keep Learning">
<meta property="og:type" content="website">
<meta property="og:title" content="YAN&#39;s Blog">
<meta property="og:url" content="http://example.com/page/8/index.html">
<meta property="og:site_name" content="YAN&#39;s Blog">
<meta property="og:description" content="Be smart! Keep Learning">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="YAN">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://example.com/page/8/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"en","comments":"","permalink":"","path":"page/8/index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>YAN's Blog</title>
  




  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">YAN's Blog</h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li>
        <li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a></li>
        <li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a></li>
        <li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a></li>
        <li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="YAN"
      src="/images/avatar.jpg">
  <p class="site-author-name" itemprop="name">YAN</p>
  <div class="site-description" itemprop="description">Be smart! Keep Learning</div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">49</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">10</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">17</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>



        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

  <a href="https://github.com/applepieiris" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/02/06/image-classification-models%E6%80%BB%E7%BB%93/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="YAN">
      <meta itemprop="description" content="Be smart! Keep Learning">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="YAN's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/02/06/image-classification-models%E6%80%BB%E7%BB%93/" class="post-title-link" itemprop="url">image classification models总结</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2023-02-06 13:39:21" itemprop="dateCreated datePublished" datetime="2023-02-06T13:39:21+08:00">2023-02-06</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">Edited on</span>
        <time title="Modified: 2023-02-28 17:09:47" itemprop="dateModified" datetime="2023-02-28T17:09:47+08:00">2023-02-28</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/computer-vision-cv/" itemprop="url" rel="index"><span itemprop="name">computer vision(cv)</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="Symbols count in article">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">Symbols count in article: </span>
      <span>7.4k</span>
    </span>
    <span class="post-meta-item" title="Reading time">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">Reading time &asymp;</span>
      <span>7 mins.</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>本博客旨在记录自己在了解<code>image classification</code>这个术语<code>computer vision</code>的一个子任务中常见的模型。耳熟能详的就是<code>ResNet</code>,<code>VGG</code>,<code>Inception</code>,<code>MobileNet</code>,
<code>Efficientnet</code>。每一个模型之间有什么区别，他们自身又有哪些变种，比如<code>VGG</code>，它拥有<code>VGG16,VGG19</code>等，<code>ResNet</code>又有很多，单是查看<code>Tensorflow</code>的官方文档就会发现在<code>tf.keras.applications</code>模块下，就有很多模型架构可选（也都有预训练参数）。整理这个博客的目的在于让自己对这些模型之间的差别有所了解，这样在不同的任务中才会知道使用什么样的模型架构来handle自己的数据。</p>
<p>在整理这篇博客的过程中，我也去搜了有没有<code>image classification</code>这个单任务上的<code>review</code>文章，文章都挺多的，筛选之后推荐这篇<a target="_blank" rel="noopener" href="https://www.mdpi.com/2072-4292/13/22/4712">Review of Image
Classification Algorithms Based on Convolutional Neural
Networks</a>.这篇文章主要是介绍基于CNN的一些模型，共有三个章节。重点是第二章节梳理了<code>CNN-based</code>的一些模型，包括本文想要<code>cover</code>的<code>VGG</code>，<code>inception</code>，<code>resnet</code>，<code>mobilenet</code>。重点关注图像分类算法的小伙伴可以通读一下这篇文章。</p>
<figure>
<img src="/2023/02/06/image-classification-models%E6%80%BB%E7%BB%93/image-20230207094857739-16757345394748.png" alt="Review of Image Classification Algorithms Based on Convolutional Neural Networks第二章节目录">
<figcaption aria-hidden="true">Review of Image Classification Algorithms
Based on Convolutional Neural Networks第二章节目录</figcaption>
</figure>
<h1 id="vgg">VGG</h1>
<p>首次提出在2014年的<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1409.1556">paper</a></p>
<figure>
<img src="/2023/02/06/image-classification-models%E6%80%BB%E7%BB%93/vgg16.png" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>上图中包含13个卷积层和3个全连接层，是<code>VGG16</code>的结构。而<code>VGG19</code>包含了16个卷积层和3个全连接层：</p>
<figure>
<img src="/2023/02/06/image-classification-models%E6%80%BB%E7%BB%93/1dNYBNBDP7ZvckfOSYzHxIw.jpeg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p><code>VGG</code>系列就是<code>VGG16</code>和<code>VGG19</code>，两者的区别在于19用了更多的卷积层。<code>Tensorflow</code>也提供了这两个模型的黑盒子实现供大家使用。</p>
<h1 id="resnet">ResNet</h1>
<p>首次提出在2016年的<a target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf">paper</a>，其中最重要的就是网络中的<code>residual block</code>:</p>
<figure>
<img src="/2023/02/06/image-classification-models%E6%80%BB%E7%BB%93/1_nmPcwwnsHE-AC69ASkj9w.jpeg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>在作者的原文中我们可以发现，文章中提出的Resnet是34层，也就是ResNet34。在具体实现的时候，作者在每一个卷积操作之后（激活函数之前）加上了batch
Normalization。在<code>Module: tf.keras.applications.resnet</code><a target="_blank" rel="noopener" href="https://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet">Tensorflow
applications
resnet</a>中现在只有ResNet101，152，50三个版本，其中ResNet50和ResNet34的区别在于：前者使用三个卷积一个block，后者是2个卷积一个block.
ResNet50表现更优异。ResNet101和ResNet152在一个block内使用了更多的卷积layer。</p>
<p>以上所说的都是resnet v1，后来同一个作者又发表了<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1603.05027.pdf">Identity Mappings in Deep
Residual Networks</a>,提出了ResNet
v2。同样我们在tensorflow中也可以看到模块<code>Module: tf.keras.applications.resnet_v2</code>，同样的也有50，101，152三个版本的model。</p>
<p>v1和v2的区别在于：</p>
<figure>
<img src="/2023/02/06/image-classification-models%E6%80%BB%E7%BB%93/image-20230206150618805-16756671800395.png" alt="ResNet v1 and ResNet v2">
<figcaption aria-hidden="true">ResNet v1 and ResNet v2</figcaption>
</figure>
<p>以上只是概念上的解释，看代码会更合适一点，其中<code>Deep Residual Learning for Image Recognition</code>文章中也给出了34，50，101，152等几个模型在实现中注意的细节：</p>
<figure>
<img src="/2023/02/06/image-classification-models%E6%80%BB%E7%BB%93/image-20230206153053177-16756686549546.png" alt="image-20230206153053177">
<figcaption aria-hidden="true">image-20230206153053177</figcaption>
</figure>
<p>ResNet34 V1中，一个resnet
block是由两个卷积layer组成的，同时它和V2的一个区别就在于X进来后就先进行卷积运算，也就是上图中的weight</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> keras.activations <span class="keyword">import</span> relu</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.layers <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> Model</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> layers <span class="keyword">as</span> Layers</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ResBlock</span>(<span class="params">Model</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, channels, stride=<span class="number">1</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(ResBlock, self).__init__(name=<span class="string">&#x27;ResBlock&#x27;</span>)</span><br><span class="line">        self.flag = (stride != <span class="number">1</span>)</span><br><span class="line">        self.conv1 = Conv2D(channels, <span class="number">3</span>, stride, padding=<span class="string">&#x27;same&#x27;</span>)</span><br><span class="line">        self.bn1 = BatchNormalization()</span><br><span class="line">        self.conv2 = Conv2D(channels, <span class="number">3</span>, padding=<span class="string">&#x27;same&#x27;</span>)</span><br><span class="line">        self.bn2 = BatchNormalization()</span><br><span class="line">        self.relu = ReLU()</span><br><span class="line">        <span class="keyword">if</span> self.flag:</span><br><span class="line">            self.bn3 = BatchNormalization()</span><br><span class="line">            self.conv3 = Conv2D(channels, <span class="number">1</span>, stride)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x1 = self.conv1(x)</span><br><span class="line">        x1 = self.bn1(x1)</span><br><span class="line">        x1 = self.relu(x1)</span><br><span class="line">        x1 = self.conv2(x1)</span><br><span class="line">        x1 = self.bn2(x1)</span><br><span class="line">        <span class="keyword">if</span> self.flag:</span><br><span class="line">            x = self.conv3(x)</span><br><span class="line">            x = self.bn3(x)</span><br><span class="line">        x1 = Layers.add([x, x1])</span><br><span class="line">        x1 = self.relu(x1)</span><br><span class="line">        <span class="keyword">return</span> x1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ResNet34</span>(<span class="params">Model</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(ResNet34, self).__init__(name=<span class="string">&#x27;ResNet34&#x27;</span>)</span><br><span class="line">        self.conv1 = Conv2D(<span class="number">64</span>, <span class="number">7</span>, <span class="number">2</span>, padding=<span class="string">&#x27;same&#x27;</span>)</span><br><span class="line">        self.bn = BatchNormalization()</span><br><span class="line">        self.relu = ReLU()</span><br><span class="line">        self.mp1 = MaxPooling2D(<span class="number">3</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        self.conv2_1 = ResBlock(<span class="number">64</span>)</span><br><span class="line">        self.conv2_2 = ResBlock(<span class="number">64</span>)</span><br><span class="line">        self.conv2_3 = ResBlock(<span class="number">64</span>)</span><br><span class="line"></span><br><span class="line">        self.conv3_1 = ResBlock(<span class="number">128</span>, <span class="number">2</span>)</span><br><span class="line">        self.conv3_2 = ResBlock(<span class="number">128</span>)</span><br><span class="line">        self.conv3_3 = ResBlock(<span class="number">128</span>)</span><br><span class="line">        self.conv3_4 = ResBlock(<span class="number">128</span>)</span><br><span class="line"></span><br><span class="line">        self.conv4_1 = ResBlock(<span class="number">256</span>, <span class="number">2</span>)</span><br><span class="line">        self.conv4_2 = ResBlock(<span class="number">256</span>)</span><br><span class="line">        self.conv4_3 = ResBlock(<span class="number">256</span>)</span><br><span class="line">        self.conv4_4 = ResBlock(<span class="number">256</span>)</span><br><span class="line">        self.conv4_5 = ResBlock(<span class="number">256</span>)</span><br><span class="line">        self.conv4_6 = ResBlock(<span class="number">256</span>)</span><br><span class="line"></span><br><span class="line">        self.conv5_1 = ResBlock(<span class="number">512</span>, <span class="number">2</span>)</span><br><span class="line">        self.conv5_2 = ResBlock(<span class="number">512</span>)</span><br><span class="line">        self.conv5_3 = ResBlock(<span class="number">512</span>)</span><br><span class="line"></span><br><span class="line">        self.pool = GlobalAveragePooling2D()</span><br><span class="line">        self.fc1 = Dense(<span class="number">512</span>, activation=<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">        self.dp1 = Dropout(<span class="number">0.5</span>)</span><br><span class="line">        self.fc2 = Dense(<span class="number">512</span>, activation=<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">        self.dp2 = Dropout(<span class="number">0.5</span>)</span><br><span class="line">        self.fc3 = Dense(<span class="number">64</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x = self.conv1(x)</span><br><span class="line">        x = self.bn(x)</span><br><span class="line">        x = self.relu(x)</span><br><span class="line">        x = self.mp1(x)</span><br><span class="line"></span><br><span class="line">        x = self.conv2_1(x)</span><br><span class="line">        x = self.conv2_2(x)</span><br><span class="line">        x = self.conv2_3(x)</span><br><span class="line"></span><br><span class="line">        x = self.conv3_1(x)</span><br><span class="line">        x = self.conv3_2(x)</span><br><span class="line">        x = self.conv3_3(x)</span><br><span class="line">        x = self.conv3_4(x)</span><br><span class="line"></span><br><span class="line">        x = self.conv4_1(x)</span><br><span class="line">        x = self.conv4_2(x)</span><br><span class="line">        x = self.conv4_3(x)</span><br><span class="line">        x = self.conv4_4(x)</span><br><span class="line">        x = self.conv4_5(x)</span><br><span class="line">        x = self.conv4_6(x)</span><br><span class="line"></span><br><span class="line">        x = self.conv5_1(x)</span><br><span class="line">        x = self.conv5_2(x)</span><br><span class="line">        x = self.conv5_3(x)</span><br><span class="line"></span><br><span class="line">        x = self.pool(x)</span><br><span class="line">        x = self.fc1(x)</span><br><span class="line">        x = self.dp1(x)</span><br><span class="line">        x = self.fc2(x)</span><br><span class="line">        x = self.dp2(x)</span><br><span class="line">        x = self.fc3(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = ResNet34()</span><br><span class="line">model.build(input_shape=(<span class="number">1</span>, <span class="number">480</span>, <span class="number">480</span>, <span class="number">3</span>))</span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure>
<h1 id="inception">Inception</h1>
<p>已经有不少博客在科普Inception系列模型的区别<a target="_blank" rel="noopener" href="https://towardsdatascience.com/a-simple-guide-to-the-versions-of-the-inception-network-7fc52b863202">A
Simple Guide to the Versions of the Inception Network</a></p>
<p>首先提出该模型的是2014年的<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1409.4842v1.pdf">Going deeper with
convolutions</a> Inception
V1（GoogleNet）,然后又分别有了好几个变体：<code>Inception V2，Inception V3，Inception V4</code>，<a target="_blank" rel="noopener" href="http://arxiv.org/abs/1602.07261">Inception-ResNet-v2</a>。和<code>ResNet</code>一样，<code>Inception</code>网络中一个重要的<code>module</code>是<code>Inception Module</code>：</p>
<figure>
<img src="/2023/02/06/image-classification-models%E6%80%BB%E7%BB%93/image-20230206161239990-16756711610527.png" alt="Inception Module">
<figcaption aria-hidden="true">Inception Module</figcaption>
</figure>
<p>其中这些Network中被广泛使用的是<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1512.00567v3.pdf">Inception_v3</a>和<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1602.07261.pdf">Inception-ResNet-v2</a>.</p>
<h1 id="mobilenet">MobileNet</h1>
<blockquote>
<p>The idea behind MobileNet is to use depthwise separable convolutions
to build loghter deep neural networks. In regular convolutional layer,
the convolution kernel or filter is applied to all of the channels of
the input image, by doing weighted sum of the input pixels with the
filter and then slides to the next input pixels across the
images.MobileNet uses this regular convolution only in the first layer.
The next layers are the depthwise separable convolutions which are the
combination of the depthwise and pointwise convolution. The depthwise
convolution does the convolution on each channel separately. If the
image has three channels, therefore, the output image also has three
channels. This depthwise convolution is used to filter the input
channels. The next step is the pointwise convolution, which is similar
to the regular convolution but with a 1x1 filter. The purpose of
pointwise convolution is to merge the output channels of the depthwise
convolution to create new features. By doing so, the computational work
needed to be done is less than the regular convolutional networks.</p>
<p>引用自<a target="_blank" rel="noopener" href="https://medium.com/@fransiska26/the-differences-between-inception-resnet-and-mobilenet-e97736a709b0">the-differences-between-inception-resnet-and-mobilenet</a></p>
</blockquote>
<p><code>MobileNet</code>使用了两种卷积形式，<code>depthwise</code>和<code>pointwise</code>，后者就是我们常见的卷积操作，只是使用的是1✖1的卷积核，input
image有多少个<code>channel</code>，<code>filter</code>就会延展为几个<code>channel</code>，比如输入进来的<code>channel</code>数是3，那么一个<code>3*3</code>大小的filter就会extend成3✖3✖3的一个立方体，然后这27个数分别禹输入image对应的区域做乘积之后相加取和。但是<code>depthwise</code>卷积是对每一个<code>channel</code>分别做卷积，如果输入图片有三个<code>channel</code>，那么输出的也会是三个<code>channel</code>。如图：</p>
<figure>
<img src="/2023/02/06/image-classification-models%E6%80%BB%E7%BB%93/image-20230207132331415.png" alt="depthwise convolution">
<figcaption aria-hidden="true">depthwise convolution</figcaption>
</figure>
<p><code>tensorflow</code>中有<code>DepthwiseConv2D</code>这个<a target="_blank" rel="noopener" href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/DepthwiseConv2D">layer</a>,它对于<code>depthwise convolution</code>的解释是：</p>
<blockquote>
<p>Depthwise convolution is a type of convolution in which each input
channel is convolved with a different kernel (called a depthwise
kernel). You can understand depthwise convolution as the first step in a
depthwise separable convolution.</p>
</blockquote>
<p><code>MobileNetV2</code>主要引进了<code>Inverted residuals</code>和<code>linear bottlenecks</code>去解决在<code>depthwise</code>卷积操作中卷积核的参数往往是0的问题</p>
<h1 id="other-topics">other topics</h1>
<p>在阅读<a target="_blank" rel="noopener" href="https://www.mdpi.com/2072-4292/13/22/4712">Review of
Image Classification Algorithms Based on Convolutional Neural
Networks</a>的最后一章节时，作者不仅介绍了现在research和industry领域用的比较多的image
classification的模型，也给出了各个模型在image-net数据集上的accuracy。在总结章，作者还提出了一些结论性的发现，我觉得蛮收益的，将文章的观点整理在这里。</p>
<ol type="1">
<li>2012年到2017年主要提供了日后用于分类的basic
CNN模型架构，这期间的模型架构有2012的alexnet，2014年的vgg，2014年的inception，2015年的resnet，2017年提出了attention加cnn的架构</li>
<li>attention加入到cnn之后形成了新的模型，也因此提高了模型的performance。现在很多模型会将SE
block嵌入到模型架构中去，我查了下这个SE
block是SEnet中的一个block，squeeze and excitation block。<a target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content_cvpr_2018/papers/Hu_Squeeze-and-Excitation_Networks_CVPR_2018_paper.pdf">SEnet</a>是在2017年提出的，这个知识点待补充</li>
<li>超参数的选择对于CNN网络的performance影响很大，很多的工作在着力于减少超参数的个数以及replace
them with other composite coefficients。</li>
<li>手动设计一个performance很好的网络往往需要很多effort，<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Neural_architecture_search">NAS
search</a> （neural architecture search）可以让这个过程变得更简单</li>
<li>想要提升模型的performance，不仅仅需要将关注力放在模型架构的设计上，data
augmentation,transfer learning,training
strategies也可以帮助我们提高模型的准确度。在transfer learning上，paper：
Large Scale Learning of General Visual Representations for Transfer
总结了一些在不同的task上如何利用transfer
learning取得很好的performance的办法。</li>
</ol>
<hr>
<p>CNN model 还面临的挑战：</p>
<ol type="1">
<li>lightweight
models比如mobileNet系列的轻量级模型往往需要牺牲accuracy来提高efficiency。未来在embedded系统上，CNN的运行效率值得去explore</li>
<li>cnn模型在semi-supervised和unsupervised上的发挥不如NLP领域。</li>
</ol>
<hr>
<p>future directions:</p>
<ol type="1">
<li>重视vision transformer.
如何将卷积和transformer有效结合起来是当前的一个热点。目前的SOTA
network是 <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2106.04803">CoAtNet</a>，在image
net数据集上的accuracy是90.88，确实是目前在image
net数据集上performance最高的模型架构。值得读一下，mark！</li>
<li>有一些关于CNN的传统技术可能会成为阻碍CNN发展的重要因素，诸如：activation
function的选择，dropout，batch normalization。</li>
</ol>
<h1 id="senet-2017">SENet 2017</h1>
<p>原文 <a target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content_cvpr_2018/papers/Hu_Squeeze-and-Excitation_Networks_CVPR_2018_paper.pdf">SEnet</a>，是由自动驾驶公司Momenta在2017年公布的一种全新的图像识别结构，它通过对特征通道间的相关性进行建模，把重要的特征进行强化来提升准确率。这个结构是2017
ILSVR竞赛的冠军，top5的错误率达到了2.251%，比2016年的第一名还要低25%，可谓提升巨大。</p>
<h1 id="coatnet">CoAtNet</h1>
<h1 id="reference">Reference</h1>
<ol type="1">
<li><a target="_blank" rel="noopener" href="https://towardsdatascience.com/architecture-comparison-of-alexnet-vggnet-resnet-inception-densenet-beb8b116866d">Architecture
comparison of AlexNet, VGGNet, ResNet, Inception, DenseNet</a></li>
<li><a target="_blank" rel="noopener" href="https://medium.com/analytics-vidhya/vggnet-architecture-explained-e5c7318aa5b6">VGGNet
Architecture Explained</a></li>
<li><a target="_blank" rel="noopener" href="https://viso.ai/deep-learning/resnet-residual-neural-network/">resnet-residual-neural-network
Resnet系列网络架构的区别</a></li>
</ol>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/01/04/tensorflow%E4%B8%ADlstm-GRU/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="YAN">
      <meta itemprop="description" content="Be smart! Keep Learning">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="YAN's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/01/04/tensorflow%E4%B8%ADlstm-GRU/" class="post-title-link" itemprop="url">tensorflow中lstm,GRU</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2023-01-04 10:19:57" itemprop="dateCreated datePublished" datetime="2023-01-04T10:19:57+08:00">2023-01-04</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">Edited on</span>
        <time title="Modified: 2023-03-13 09:59:22" itemprop="dateModified" datetime="2023-03-13T09:59:22+08:00">2023-03-13</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/tensorflow/" itemprop="url" rel="index"><span itemprop="name">tensorflow</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="Symbols count in article">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">Symbols count in article: </span>
      <span>2.7k</span>
    </span>
    <span class="post-meta-item" title="Reading time">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">Reading time &asymp;</span>
      <span>2 mins.</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="gru">GRU</h1>
<figure>
<img src="/2023/01/04/tensorflow%E4%B8%ADlstm-GRU/LSTM3-var-GRU.png" alt="GRU">
<figcaption aria-hidden="true">GRU</figcaption>
</figure>
<p>其实单看输出，GRU的输出是和简单的RNN一样的，都只有一个hidden_state。所以在tensorflow中它的输出其实和RNN
layer一样：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">inputs = tf.random.normal([<span class="number">32</span>, <span class="number">10</span>, <span class="number">8</span>])</span><br><span class="line">gru = tf.keras.layers.GRU(<span class="number">4</span>)</span><br><span class="line">output = gru(inputs)</span><br><span class="line"><span class="built_in">print</span>(output.shape)</span><br><span class="line">&gt;&gt; (<span class="number">32</span>, <span class="number">4</span>)</span><br></pre></td></tr></table></figure>
<p>其中有两个可以传递给GRU的参数，一个是return_state，一个是return_sequence。两个值都是bool类型。如果单独传递return_sequence=True，那么输出将只有一个值，也就是每一个时间步的序列：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">gru = tf.keras.layers.GRU(<span class="number">4</span>, return_sequences=<span class="literal">True</span>)</span><br><span class="line">output = gru(inputs)</span><br><span class="line"><span class="built_in">print</span>(output.shape)</span><br><span class="line">&gt;&gt; (<span class="number">32</span>, <span class="number">10</span>, <span class="number">4</span>)</span><br></pre></td></tr></table></figure>
<p>如果单独传递return_state=True，那么输出将会是两个值，可以仔细看官方文档中的说明是<code>Boolean. Whether to return the last state in addition to the output. Default:</code>False.`也就是output和最后的hidden_state会一起输出，并且output会等于final_state：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">gru = tf.keras.layers.GRU(<span class="number">4</span>, return_state=<span class="literal">True</span>)</span><br><span class="line">output, final_state = gru(inputs)</span><br><span class="line"><span class="built_in">print</span>(output.shape)</span><br><span class="line"><span class="built_in">print</span>(final_state.shape) <span class="comment"># output=final_state</span></span><br><span class="line">&gt;&gt; (<span class="number">32</span>, <span class="number">4</span>)</span><br><span class="line">&gt;&gt; (<span class="number">32</span>, <span class="number">4</span>)</span><br></pre></td></tr></table></figure>
<p>如果单独传递return_sequences=True，LSTM将只返回整个序列！</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">lstm = tf.keras.layers.LSTM(<span class="number">4</span>,return_sequences=<span class="literal">True</span>)</span><br><span class="line">inputs = tf.random.normal([<span class="number">32</span>, <span class="number">10</span>, <span class="number">8</span>])</span><br><span class="line">whole_seq_output = lstm(inputs)</span><br><span class="line"><span class="built_in">print</span>(whole_seq_output.shape)</span><br><span class="line">&gt;&gt; (<span class="number">32</span>, <span class="number">10</span>, <span class="number">4</span>)</span><br></pre></td></tr></table></figure>
<p>那如果两个值都设置成<code>True</code>呢？这将返回两个输出，第一个输出是整个序列，第二个输出是最终的state。注意这里并没有<code>output</code>了，因为<code>output</code>其实是<code>sequence</code>中最后一个序列<code>sequence[:,-1,:]</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">gru = tf.keras.layers.GRU(<span class="number">4</span>, return_sequences=<span class="literal">True</span>, return_state=<span class="literal">True</span>)</span><br><span class="line">whole_sequence_output, final_state = gru(inputs)</span><br><span class="line"><span class="built_in">print</span>(whole_sequence_output.shape)</span><br><span class="line"><span class="built_in">print</span>(final_state.shape)</span><br><span class="line">&gt;&gt; (<span class="number">32</span>, <span class="number">10</span>, <span class="number">4</span>)</span><br><span class="line">(<span class="number">32</span>, <span class="number">4</span>)</span><br></pre></td></tr></table></figure>
<h1 id="lstm">LSTM</h1>
<p>轮到LSTM，因为架构上跟GRU有点区别，所以在返回结果上就多了一个carry_state.</p>
<figure>
<img src="/2023/01/04/tensorflow%E4%B8%ADlstm-GRU/LSTM3-var-peepholes.png" alt="LSTM">
<figcaption aria-hidden="true">LSTM</figcaption>
</figure>
<p>想要了解LSTM的具体计算，参考<a target="_blank" rel="noopener" href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/">博客</a></p>
<p>在tensorflow中一样有return_state和return_sequences：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">inputs = tf.random.normal([<span class="number">32</span>, <span class="number">10</span>, <span class="number">8</span>])</span><br><span class="line">lstm = tf.keras.layers.LSTM(<span class="number">4</span>)</span><br><span class="line">output = lstm(inputs)</span><br><span class="line"><span class="built_in">print</span>(output.shape)</span><br><span class="line">&gt;&gt; (<span class="number">32</span>, <span class="number">4</span>)</span><br></pre></td></tr></table></figure>
<p>如果单独传递return_state，这里和GRU不一样的地方在于lstm有两个state，一个是memory_state一个是carry_state</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">lstm = tf.keras.layers.LSTM(<span class="number">4</span>,return_state=<span class="literal">True</span>)</span><br><span class="line">output, final_memory_state, final_carry_state = lstm(inputs)</span><br><span class="line"><span class="built_in">print</span>(output.shape)</span><br><span class="line"><span class="built_in">print</span>(final_memory_state.shape) <span class="comment"># final_memory_state=output</span></span><br><span class="line"><span class="built_in">print</span>(final_carry_state.shape)</span><br><span class="line">&gt;&gt; (<span class="number">32</span>, <span class="number">4</span>)</span><br><span class="line">&gt;&gt; (<span class="number">32</span>, <span class="number">4</span>)</span><br><span class="line">&gt;&gt; (<span class="number">32</span>, <span class="number">4</span>)</span><br></pre></td></tr></table></figure>
<p>如果同时设置True</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">lstm = tf.keras.layers.LSTM(<span class="number">4</span>,return_sequences=<span class="literal">True</span>,return_state=<span class="literal">True</span>)</span><br><span class="line">whole_seq_output, final_memory_state, final_carry_state = lstm(inputs)</span><br><span class="line"><span class="built_in">print</span>(whole_seq_output.shape)</span><br><span class="line"><span class="built_in">print</span>(final_memory_state.shape) <span class="comment"># final_memory_state=whole_seq_output[:,-1,:]</span></span><br><span class="line"><span class="built_in">print</span>(final_carry_state.shape)</span><br><span class="line">&gt;&gt; (<span class="number">32</span>, <span class="number">10</span>, <span class="number">4</span>)</span><br><span class="line">&gt;&gt; (<span class="number">32</span>, <span class="number">4</span>)</span><br><span class="line">&gt;&gt; (<span class="number">32</span>, <span class="number">4</span>)</span><br></pre></td></tr></table></figure>
<h1 id="gru-vs-lstm">GRU vs LSTM</h1>
<p>至于我们在训练模型的时候选择哪一个cell作为RNN的cell，cs224n课程给出的答案是：</p>
<blockquote>
<p>Researchers have proposed many gated RNN variants, but LSTM and GRU
are the most widely-used.</p>
<p>Rule of thumb: LSTM is a good default choice (especially if your data
has particularly long dependencies, or you have lots of training data);
Switch to GRUs for speed and fewer parameters.</p>
</blockquote>
<p>LSTM doesn’t guarantee that there is no vanishing/exploding gradient,
but it does provide an easier way for the model to learn long-distance
dependencies.</p>
<p>在2023年的今天，lstm也不再是研究者青睐的对象，最火的模型变成了Transformer：</p>
<figure>
<img src="/2023/01/04/tensorflow%E4%B8%ADlstm-GRU/image-20230313095438649.png" alt="image-20230313095438649">
<figcaption aria-hidden="true">image-20230313095438649</figcaption>
</figure>
<p>这里也贴出2022年的最新WMT的<a target="_blank" rel="noopener" href="https://www.statmt.org/wmt22/pdf/2022.wmt-1.1.pdf">结果</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/11/02/R-CNN-vs-SPP-vs-Fast-R-CNN-vs-Faster-R-CNN/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="YAN">
      <meta itemprop="description" content="Be smart! Keep Learning">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="YAN's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/11/02/R-CNN-vs-SPP-vs-Fast-R-CNN-vs-Faster-R-CNN/" class="post-title-link" itemprop="url">R-CNN vs SPP vs Fast R-CNN vs Faster R-CNN</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-11-02 14:25:33" itemprop="dateCreated datePublished" datetime="2022-11-02T14:25:33+08:00">2022-11-02</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">Edited on</span>
        <time title="Modified: 2023-02-08 11:36:00" itemprop="dateModified" datetime="2023-02-08T11:36:00+08:00">2023-02-08</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/computer-vision-cv/" itemprop="url" rel="index"><span itemprop="name">computer vision(cv)</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="Symbols count in article">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">Symbols count in article: </span>
      <span>6.2k</span>
    </span>
    <span class="post-meta-item" title="Reading time">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">Reading time &asymp;</span>
      <span>6 mins.</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>最近在object
detection任务上读这几篇文章，见识到神仙打架。一开始我只是关注image
segmentation的任务，其中instance
segmentation任务中Mask-RCNN是其中比较火的一个model，所以就把跟这个模型相关的几个模型都找出来看了看。这里想记录下这几天看这几篇论文的心得体会，如果有写的不正确的地方，欢迎批评指正。</p>
<p>其实去仔细看这几篇论文很有意思，梳理一下时间线就是：</p>
<ol type="1">
<li><p><strong>2014</strong>年Girshick提出了RCNN，用于解决accurate
object detection 和 semantic
segmentation。该模型有一个drawbacks是每次一张图片输入进来，需要产生~2000个region
proposals，这些region的大小都是不一致的，但我们对图片进行分类的下游网络都是需要fixed
size的图片，那怎么办呢？作者提出使用wraped方法，具体可以参考作者的论文。总之最终我们输入到SVM也就是分类器的region图片大小都是一致的。</p></li>
<li><p>为了解决每次输入网络的图片大小怎么样才能变成fixed
size的vector，<strong>2015</strong>年he kaiming提出了SPP（spatial
pyramid pooling），跟前者RCNN不一样的地方在于：1) 将region
proposal的方法用在了图片输入cnn网络得到的feature map上，2)从feature
map选择出来的region
proposal不还是不一样大小么？作者没有使用wrap的方法，而是提出了一个SPP
layer,这个layer可以接受任何大小的图片，最终都会转化成一个fixed
size的向量，这样就可以轻松输入进SVM或者Dense layer进行分类了。</p></li>
<li><p>收到SPP的启发，Girshick在<strong>2015</strong>年提出了Fast-RCNN，将SPP
layer重新替换成ROI Pooling，经过ROI pooling，输出的并不是SPP
layer输出的金字塔式的向量了，而是只有一个。 <a target="_blank" rel="noopener" href="https://analyticsindiamag.com/r-cnn-vs-fast-r-cnn-vs-faster-r-cnn-a-comparative-guide/">参考博客</a></p></li>
<li><p>经过前一轮的battle，虽然各自的模型都提出了自己的独特方法，但是无论是SPP
Net还是Fast-RCNN都没有提出在选择ROI(region of
interest)的方法。<strong>2016</strong>年He
Kaiming再次强势入场，提出了产生region
proposal的方法，它使用了一个单独的CNN网络来获取region
proposal.得到了这些proposal之后再将他们传递给Roi Pooling
layer，后面的过程和fast RCNN一致。 这篇Faster-RCNN的方法作者中有he
kaiming和Girshick，这里致敬下sun jian，感谢为computer
vision领域贡献的灵感和创造。</p></li>
</ol>
<h1 id="mask-rcnn">Mask-RCNN</h1>
<p>Mask-RCNN是Region-based CNN系列中的一个算法，用于解决instance
segmentation的问题，instance segmentation的难点在于我们不仅要做object
detection，而且需要将object的准确轮廓给识别出来，同时做出分类这是什么object。在<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1703.06870">Mask-RCNN</a></p>
<p>中，related
work一章节对RCNN这一系列的模型做了准确概括，建议大家读原文：</p>
<blockquote>
<p>The Region-based CNN (R-CNN) approach [13] to bounding-box object
detection is to attend to a manageable number of candidate object
regions [42, 20] and evaluate convolutional networks [25, 24]
independently on each RoI. R-CNN was extended [18, 12] to allow
attending to RoIs on feature maps using RoIPool, leading to fast speed
and better accuracy. Faster R-CNN [36] advanced this stream by learning
the attention mechanism with a Region Proposal Network (RPN). Faster
R-CNN is flexible and robust to many follow-up improvements (e.g., [38,
27, 21]), and is the current leading framework in several
benchmarks.</p>
</blockquote>
<p>在Mask-RCNN的文章中提出了一种新的ROIAlign
Layer，主要是为了解决Faster-Rcnn的网络中ROI pooling
layer的问题。在此补充下ROI pooling是怎么将不同size的ROI（region of
interest）都变成fixed-size的feature map的：</p>
<figure>
<img src="/2022/11/02/R-CNN-vs-SPP-vs-Fast-R-CNN-vs-Faster-R-CNN/image-20221128165901678-16696259446601.png" alt="ROI Pooling Layer">
<figcaption aria-hidden="true">ROI Pooling Layer</figcaption>
</figure>
<p>上图是将5*4大小的ROI变成了2✖2大小的feature
map。这种方式带来的影响就是可能在提取的extracted
features和ROI之间造成misalignments。但是这种misalignments并不会在faster-rcnn中对分类造成很大的影响，但如果要用这个ROI做segmentation的话就可能会造成巨大的影响，因此作者提出了一个ROIAlign
Layer。</p>
<blockquote>
<p>如果有小伙伴想对照code看这篇paper，可以参考<a target="_blank" rel="noopener" href="https://github.com/matterport/Mask_RCNN/blob/3deaec5d902d16e1daf56b62d5971d428dc920bc/mrcnn/model.py#L486">tensorflow实现</a>。如果你对pytorch更熟悉可以参考paper中给出的官方github地址的实现。有一篇博客详细介绍了tensorlfow的实现，参见<a target="_blank" rel="noopener" href="https://blog.paperspace.com/mask-r-cnn-in-tensorflow-2-0/">blog</a></p>
</blockquote>
<p>在MaskRCNN中使用了faster-rcnn中提出的RPN来产生ROI，然后才使用上面提到的ROI
Algin。RPN的具体细节参见fatser-rcnn原文和本博客的<a href="#RPN(Region%20Proposal%20Network)">第二章节</a></p>
<h1 id="rpnregion-proposal-network">RPN(Region Proposal Network)</h1>
<p>RPN
是在faster-rcnn中提出来的网络，主要是为了解决在rcnn和fast-rcnn两个前置模型中产生ROI的耗时问题，之前产生ROI主要是依靠Selected
Search。在读mask-rcnn的paper时发现这个网络的细节不甚了解，这里补充记录一下。感兴趣的朋友可以阅读<a target="_blank" rel="noopener" href="http://arxiv.org/abs/1506.01497">paper</a>的第3.2节。</p>
<p>RPN在output长方体的ROI的同时，也会给每一个ROI产生一个Objectness
score。看原文的时候作者是以sliding
window的方式来讲解的，一开始看的有点懵。但其实就是卷积层的计算过程的拆解，我们先按照作者的思路来看RPN做了什么。</p>
<figure>
<img src="/2022/11/02/R-CNN-vs-SPP-vs-Fast-R-CNN-vs-Faster-R-CNN/image-20221129160354668-16697090363711.png" alt="faster-Rcnn">
<figcaption aria-hidden="true">faster-Rcnn</figcaption>
</figure>
<p>RPN的输入是经过一系列卷积层之后的feature
map，在这个map上，我们在上面再做一些运算：</p>
<figure>
<img src="/2022/11/02/R-CNN-vs-SPP-vs-Fast-R-CNN-vs-Faster-R-CNN/image-20221129160504387-16697091055822.png" alt="RPN network">
<figcaption aria-hidden="true">RPN network</figcaption>
</figure>
<p>针对一个window（n✖n），RPN做的就是将这个window映射到一个低维度的feature上，图上是256维的向量，然后我们再接两个dense
layer，一个用于预测box，一个用于做分类。k的意思是在每一个sliding
window上我们都维护了k个anchor，这个概念和yolo里一致。所以在每一个sliding-window上我们都可以得出来4k个box和2k个分类结果（是否有object的概率），这个anchor
box是和sliding-window的中心点绑定的，所以如果RPN的输入是一个W×H的feature
map，那么我们就会有W×H×k个anchors。</p>
<p>那么我们知道RPN是怎么计算的了，然后在训练阶段还有一些tricks。作者对每一个anchor都赋予了一个class
label，赋予positive的anchor为 1) anchor和 groud truth的box有最高的IOU 2)
如果anchor与groud
truth的box的IOU大于0.7。这两种anchor都会被赋予positive的标签，也就是代表它里面有object。对于哪些和任何groud
truth
box的IOU都小于0.3的anchor，赋予negtive的标签。在为RPN产生训练数据时，对于所有的anchors都有一个class
label，也就是它里面是否包含object。对于box的训练数据的处理有一点不一样的地方。可以参考<a target="_blank" rel="noopener" href="https://github.com/matterport/Mask_RCNN/blob/3deaec5d902d16e1daf56b62d5971d428dc920bc/mrcnn/model.py#L486">tensorflow实现</a>，在<code>mrcnn/model.py</code>的<code>build_rpn_target</code>函数中：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># RPN Match: 1 = positive anchor, -1 = negative anchor, 0 = neutral</span></span><br><span class="line">rpn_match = np.zeros([anchors.shape[<span class="number">0</span>]], dtype=np.int32)</span><br><span class="line"><span class="comment"># RPN bounding boxes: [max anchors per image, (dy, dx, log(dh), log(dw))]</span></span><br><span class="line">rpn_bbox = np.zeros((config.RPN_TRAIN_ANCHORS_PER_IMAGE, <span class="number">4</span>))</span><br></pre></td></tr></table></figure>
<p>rpn_bbox的数量是提前设定好的，也就是不是对每一个anchor都会有一个box来对应，对于那些标记为positive的anchor
box才会有bbox的target。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Generate RPN trainig targets</span></span><br><span class="line"><span class="comment"># target_rpn_match is 1 for positive anchors, -1 for negative anchors</span></span><br><span class="line"><span class="comment"># and 0 for neutral anchors.</span></span><br><span class="line">target_rpn_match, target_rpn_bbox = modellib.build_rpn_targets(</span><br><span class="line">    image.shape, model.anchors, gt_class_id, gt_bbox, model.config)</span><br><span class="line">log(<span class="string">&quot;target_rpn_match&quot;</span>, target_rpn_match)</span><br><span class="line">log(<span class="string">&quot;target_rpn_bbox&quot;</span>, target_rpn_bbox)</span><br></pre></td></tr></table></figure>
<p>输出为：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">target_rpn_match         shape: (65472,)              min:   -1.00000  max:    1.00000</span><br><span class="line">target_rpn_bbox          shape: (256, 4)              min:   -5.19860  max:    2.59641</span><br></pre></td></tr></table></figure>
<p>从上面可以看出，在全局变量设置中设置的是每一张图片最多有256个anchors，所以产生的rpn_bbox
shape就是(256,4),而用于RPN训练的class
label是全部的anchors的分类label。进一步的我们可以查看其中一张图片的anchors：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">positive_anchor_ix = np.where(target_rpn_match[:] == <span class="number">1</span>)[<span class="number">0</span>]</span><br><span class="line">negative_anchor_ix = np.where(target_rpn_match[:] == -<span class="number">1</span>)[<span class="number">0</span>]</span><br><span class="line">neutral_anchor_ix = np.where(target_rpn_match[:] == <span class="number">0</span>)[<span class="number">0</span>]</span><br><span class="line">positive_anchors = model.anchors[positive_anchor_ix]</span><br><span class="line">negative_anchors = model.anchors[negative_anchor_ix]</span><br><span class="line">neutral_anchors = model.anchors[neutral_anchor_ix]</span><br><span class="line">log(<span class="string">&quot;positive_anchors&quot;</span>, positive_anchors)</span><br><span class="line">log(<span class="string">&quot;negative_anchors&quot;</span>, negative_anchors)</span><br><span class="line">log(<span class="string">&quot;neutral anchors&quot;</span>, neutral_anchors)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Apply refinement deltas to positive anchors</span></span><br><span class="line">refined_anchors = utils.apply_box_deltas(</span><br><span class="line">    positive_anchors,</span><br><span class="line">    target_rpn_bbox[:positive_anchors.shape[<span class="number">0</span>]] * model.config.RPN_BBOX_STD_DEV)</span><br><span class="line">log(<span class="string">&quot;refined_anchors&quot;</span>, refined_anchors, )</span><br></pre></td></tr></table></figure>
<p>输出：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">positive_anchors         shape: (14, 4)               min:    5.49033  max:  973.25483</span><br><span class="line">negative_anchors         shape: (242, 4)              min:  -22.62742  max: 1038.62742</span><br><span class="line">neutral anchors          shape: (65216, 4)            min: -362.03867  max: 1258.03867</span><br><span class="line">refined_anchors          shape: (14, 4)               min:    0.00000  max: 1023.99994</span><br></pre></td></tr></table></figure>
<p>即便是有65472个anchors，但其实正负anchor所占比重很小，大多数是neutral的anchor。其中对于positive的anchor，我们拥有在他们的bbox上refine过的box。</p>
<figure>
<img src="/2022/11/02/R-CNN-vs-SPP-vs-Fast-R-CNN-vs-Faster-R-CNN/positive_refined_box.png" alt="positive anchor">
<figcaption aria-hidden="true">positive anchor</figcaption>
</figure>
<p>上图中虚线画出来的是positive
anchor，实线框出来的是在这些anchor上refine过的box。</p>
<p>在训练阶段，计算loss时，对于regression loss，模型只会计算postive
anchors的regression
loss，也就是只计算那些被打上positive标签的anchor预测的box与groud-truth
box的回归loss。如果一个anchor，它的class
label在anatation阶段就是negtive的，模型并不会将它预测出来的box和ground-truth
box进行比较，他们的loss不会被计算进总的Loss。</p>
<p>关于如何训练的问题，在Faster-Rcnn的文章中给出了三种训练的算法，第一种也是文中采用的方法就是：1.
alternating training :
先把RPN单独训练，然后使用RPN产生的proposals去训练fast r-cnn.
然后将fine-tune过的RPN作为初始参数，然后再去产生proposal，再去训练fast
rcnn. 具体来说就是4步：</p>
<ol type="1">
<li>单独train RPN ： 用ImageNet pre-trained 参数做初始化，然后在region
proposal这个task上fine tune</li>
<li>利用第一步产生的proposal训练Fast-Rcnn，也就是<a href="R-CNN-vs-SPP-vs-Fast-R-CNN-vs-Faster-R-CNN/image-20221129160354668-16697090363711.png">架构图</a>中的最上面一部分，该网络也会使用ImageNet
pre-trained
参数做初始化。注意一直到这一步，两个网络都没有share任何卷积layers</li>
<li>第三步我们使用detector的network去初始化RPN，同时fix住最下面的卷积层，也就是两个网络共享的那些卷积层。这一步骤单独fine-tune
RPN的layers。</li>
<li>最后一步，fine-tune Fast-RCNN的unique的layers。</li>
</ol>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/7/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/7/">7</a><span class="page-number current">8</span><a class="page-number" href="/page/9/">9</a><span class="space">&hellip;</span><a class="page-number" href="/page/17/">17</a><a class="extend next" rel="next" href="/page/9/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">YAN</span>
</div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
      <span>Symbols count total: </span>
    <span title="Symbols count total">210k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span>Reading time total &asymp;</span>
    <span title="Reading time total">3:11</span>
  </span>
</div>

    </div>
  </footer>

  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@next-theme/pjax@0.5.0/pjax.min.js" integrity="sha256-3NkoLDrmHLTYj7csHIZSr0MHAFTXth7Ua/DDt4MRUAg=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script><script src="/js/bookmark.js"></script><script src="/js/pjax.js"></script>

  
<script src="https://cdn.jsdelivr.net/npm/hexo-generator-searchdb@1.4.0/dist/search.js" integrity="sha256-vXZMYLEqsROAXkEw93GGIvaB2ab+QW6w3+1ahD9nXXA=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>



  <script src="/js/third-party/fancybox.js"></script>

  <script src="/js/third-party/pace.js"></script>

  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js","integrity":"sha256-r+3itOMtGGjap0x+10hu6jW/gZCzxHsoKrOd7gyRSGY="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>



</body>
</html>
