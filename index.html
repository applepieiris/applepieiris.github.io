<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.2">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.loli.net/css?family=consolas:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/themes/blue/pace-theme-minimal.css">
  <script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js" integrity="sha256-gqd7YTjg/BtfqWSwsJOvndl0Bxc8gFImLEkXQT8+qj0=" crossorigin="anonymous"></script>

<script class="next-config" data-name="main" type="application/json">{"hostname":"example.com","root":"/","images":"/images","scheme":"Muse","darkmode":false,"version":"8.8.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":false,"bookmark":{"enable":true,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":"disqus","storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>
<meta name="description" content="Be smart! Keep Learning">
<meta property="og:type" content="website">
<meta property="og:title" content="YAN&#39;s Blog">
<meta property="og:url" content="http://example.com/index.html">
<meta property="og:site_name" content="YAN&#39;s Blog">
<meta property="og:description" content="Be smart! Keep Learning">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="YAN">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://example.com/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"en","comments":"","permalink":"","path":"index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>YAN's Blog</title>
  




  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">YAN's Blog</h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li>
        <li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a></li>
        <li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a></li>
        <li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a></li>
        <li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="YAN"
      src="/images/avatar.jpg">
  <p class="site-author-name" itemprop="name">YAN</p>
  <div class="site-description" itemprop="description">Be smart! Keep Learning</div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">49</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">10</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">17</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>



        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

  <a href="https://github.com/applepieiris" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/01/09/Novel-view-synthesis-NVS/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="YAN">
      <meta itemprop="description" content="Be smart! Keep Learning">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="YAN's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/01/09/Novel-view-synthesis-NVS/" class="post-title-link" itemprop="url">Novel view synthesis(NVS)</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2025-01-09 10:17:18" itemprop="dateCreated datePublished" datetime="2025-01-09T10:17:18+08:00">2025-01-09</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">Edited on</span>
        <time title="Modified: 2025-01-16 14:22:26" itemprop="dateModified" datetime="2025-01-16T14:22:26+08:00">2025-01-16</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/cv/" itemprop="url" rel="index"><span itemprop="name">cv</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="Symbols count in article">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">Symbols count in article: </span>
      <span>5.3k</span>
    </span>
    <span class="post-meta-item" title="Reading time">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">Reading time &asymp;</span>
      <span>5 mins.</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>最近刚接触到这个话题，想开一篇新博客来记录一下自己学习的过程。</p>
<p>首先我是看了两篇review了解了这个topic的主要任务：</p>
<ul>
<li>advancements in radiance field techniques for volumetric video
generation: a technical overview</li>
<li><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05658">From Capture to Display: A
Survey on Volumetric Video</a></li>
</ul>
<p>另外同步阅读了huggingface的tutorial：https://huggingface.co/learn/computer-vision-course/unit8/3d-vision/nvs。这篇博客将NVS描述为这样一个任务：</p>
<blockquote>
<p>generate views from new camera angles that are plausibly consistent
with a set of images.</p>
</blockquote>
<p>我们在对一个场景进行3D还原时，首先的输入是一系列相机在不同的视角拍摄的静态图片，通过这些图片我们对该场景下的人物以及物体进行3D建模，但相机个数是有限的，如何推算出某个没有相机的角度上的view，这就是NVS这个任务要做的事情。</p>
<p>很多方法在这个topic上提出来，大致可以分成两类：<em>1）generate an
intermediate three-dimensional representation, which is rendered from a
new viewing direction. 比如PixelNeFRF 2）direclty generated new views
without an intermediate 3D representaion</em>， 比如Zero123</p>
<h1 id="nerf">NeRF</h1>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2003.08934">NeRF: Representing Scenes
as Neural Radiance Fields for View Synthesis</a></p>
<p>2020年出的一篇文章，下面这句话就是它这个算法的精华：</p>
<blockquote>
<p>Our algorithm represents a scene using a fully-connected
(nonconvolutional) deep network, whose input is a single continuous 5D
coordinate (spatial location (x, y, z) and viewing direction (θ, φ)) and
whose output is the volume density and view-dependent emitted radiance
at that spatial location</p>
</blockquote>
<h2 id="llff-数据集">LLFF 数据集</h2>
<p>在查看NeRF的github
code时，发现作者使用了两个数据集，其中一个就是LLFF，本着学习的原则，先把<a target="_blank" rel="noopener" href="https://github.com/Fyusion/LLFF">LLFF数据集</a>搞清楚。</p>
<p>LLFF全称为Local light Field
Fusion，也是提出了一个NVS的算法。LLFF的主旨思想是：</p>
<blockquote>
<p>present a simple and reliable method for view synthesis from a set of
input images captured by a handheld camera in an irregular grid
pattern.</p>
</blockquote>
<p>简单说就是：该方法可以从一系列手持拍摄的静态图片生成一个scene，这个scene可以理解为一个3D的场景，可以用VR眼镜看的那种。</p>
<p>该<a href="(https://github.com/Fyusion/LLFF)">LLFF
repo</a>提供了非常详细的安装教程，令我比较感兴趣的是，它可以基于自己拍摄的一些静态图片生成一个scene。先来看看它的这份代码。</p>
<p>我们的输入是从一系列的images开始的，首先第一步</p>
<ol type="1">
<li>recover cammera poses</li>
</ol>
<p>这一步采用<a target="_blank" rel="noopener" href="https://github.com/colmap/colmap?tab=readme-ov-file">COLMAP</a>
实现了一个 struture from emotion + Multi-View
Stereo(MVS)的完整pipeline。这一步的输入是一系列的静态图像，输出的是这个场景下的
6-DoF camera poses和 near/far depth bounds。</p>
<p>Structure-from-Motion (SfM) <strong>is the process of reconstructing
3D structure from its projections into a series of images. The input is
a set of overlapping images of the same object, taken from different
viewpoints. The output is a 3-D reconstruction of the object, and the
reconstructed intrinsic and extrinsic camera parameters of all
images.</strong></p>
<figure>
<img src="/2025/01/09/Novel-view-synthesis-NVS/incremental-sfm.png" alt="incremental-sfm">
<figcaption aria-hidden="true">incremental-sfm</figcaption>
</figure>
<p>COLMAP使用的方法依赖于<a target="_blank" rel="noopener" href="http://ieeexplore.ieee.org/document/7780814/">Structure-from-Motion
Revisited</a>这篇文章，它将SfM分成三个步骤：</p>
<ul>
<li>feature detection and extraction</li>
</ul>
<p>这一步好理解，特征抽取，利用一个<code>apprearance descriptor f</code></p>
<ul>
<li>feature matching and geometric verification</li>
</ul>
<p><em>feature matching</em>利用前一步的features找出这一系列图片中的same
scene part。原文是这样写的：</p>
<blockquote>
<p>The na ̈ıve approach tests every image pair for scene overlap; it
searches for feature correspondences by finding the most similar feature
in image I(a) for every feature in image I(b), using a similarity metric
comparing the appearance fj of the features</p>
</blockquote>
<p>简单理解就是根据上一步抽取的features去一一比对每一对image
pair，寻找出每一对image pair中的相似feature，从而找出same scene
part。</p>
<p><em>geometric verification</em>
我觉得有点稍微难理解。上一步只是确认了每一张图片中在apperance上相似的scene
part，但有可能不是指代的这个场景下的同一个object（Point）,
所以就需要去verify上一步的match是否准确，怎么verify呢？通过projective
geometry去预估transformation</p>
<blockquote>
<p>Since matching is based solely on appearance, it is not guaranteed
that corresponding features actually map to the same scene point</p>
</blockquote>
<ul>
<li>structure and motion reconstruction</li>
</ul>
<p>Multi-View Stereo(MVS) takes the output of SfM to compute depth
and/or normal infomation for every pixel in an image.Fusion of the depth
and normal maps of multiple images in 3D then produces a dense point
cloud of the scene.</p>
<p>实现脚本为<code>imgs2poses.py</code>,
看该源代码就是基于COLMAP来做的。试着运行该脚本，测试数据用repo内的<code>download_data.sh</code>下载的数据。运行完后可以看到如下输出：</p>
<figure>
<img src="/2025/01/09/Novel-view-synthesis-NVS/image-20250114162420847.png" alt="image-20250114162420847">
<figcaption aria-hidden="true">image-20250114162420847</figcaption>
</figure>
<p>其中images是source
images，testscene下除了images这个文件夹，其他都是COLMAP生成的。具体含义参考COLMAP的<a target="_blank" rel="noopener" href="https://colmap.github.io/tutorial.html#data-structure">document</a></p>
<p>logs文件内容：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Need to run COLMAP</span><br><span class="line">Features extracted</span><br><span class="line">Features matched</span><br><span class="line">Sparse map created</span><br><span class="line">Finished running COLMAP, see data/testscene/colmap_output.txt for logs</span><br><span class="line">Post-colmap</span><br><span class="line">(&#x27;Cameras&#x27;, 5)</span><br><span class="line">(&#x27;Images #&#x27;, 20)</span><br><span class="line">(&#x27;Points&#x27;, (9906, 3), &#x27;Visibility&#x27;, (9906, 20))</span><br><span class="line">(&#x27;Depth stats&#x27;, 13.732739125795911, 118.85217973695897, 30.413495856274356)</span><br><span class="line">Done with imgs2poses</span><br></pre></td></tr></table></figure>
<p>仔细分析一下<code>imgs2poses.py</code>，一共用COLMAP执行了三条terminal命令：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># extract features</span></span><br><span class="line">feature_extractor_args = [</span><br><span class="line">        <span class="string">&#x27;colmap&#x27;</span>, <span class="string">&#x27;feature_extractor&#x27;</span>, </span><br><span class="line">            <span class="string">&#x27;--database_path&#x27;</span>, os.path.join(basedir, <span class="string">&#x27;database.db&#x27;</span>), </span><br><span class="line">            <span class="string">&#x27;--image_path&#x27;</span>, os.path.join(basedir, <span class="string">&#x27;images&#x27;</span>),</span><br><span class="line">            <span class="string">&#x27;--ImageReader.single_camera&#x27;</span>, <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line">            <span class="comment"># &#x27;--SiftExtraction.use_gpu&#x27;, &#x27;0&#x27;,</span></span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line"><span class="comment"># matching</span></span><br><span class="line">exhaustive_matcher_args = [</span><br><span class="line">        <span class="string">&#x27;colmap&#x27;</span>, match_type, </span><br><span class="line">            <span class="string">&#x27;--database_path&#x27;</span>, os.path.join(basedir, <span class="string">&#x27;database.db&#x27;</span>), </span><br><span class="line">    ]</span><br><span class="line"><span class="comment"># Sparse map create</span></span><br><span class="line">mapper_args = [</span><br><span class="line">        <span class="string">&#x27;colmap&#x27;</span>, <span class="string">&#x27;mapper&#x27;</span>,</span><br><span class="line">            <span class="string">&#x27;--database_path&#x27;</span>, os.path.join(basedir, <span class="string">&#x27;database.db&#x27;</span>),</span><br><span class="line">            <span class="string">&#x27;--image_path&#x27;</span>, os.path.join(basedir, <span class="string">&#x27;images&#x27;</span>),</span><br><span class="line">            <span class="string">&#x27;--output_path&#x27;</span>, os.path.join(basedir, <span class="string">&#x27;sparse&#x27;</span>), <span class="comment"># --export_path changed to --output_path in colmap 3.6</span></span><br><span class="line">            <span class="string">&#x27;--Mapper.num_threads&#x27;</span>, <span class="string">&#x27;16&#x27;</span>,</span><br><span class="line">            <span class="string">&#x27;--Mapper.init_min_tri_angle&#x27;</span>, <span class="string">&#x27;4&#x27;</span>,</span><br><span class="line">            <span class="string">&#x27;--Mapper.multiple_models&#x27;</span>, <span class="string">&#x27;0&#x27;</span>,</span><br><span class="line">            <span class="string">&#x27;--Mapper.extract_colors&#x27;</span>, <span class="string">&#x27;0&#x27;</span>,</span><br><span class="line">    ]</span><br></pre></td></tr></table></figure>
<p>对照colmap cli的<a target="_blank" rel="noopener" href="https://colmap.github.io/cli.html">guidebook</a>,
作者使用了前三个命令，dense部分没有继续生成。想要知道它output出来的这些.bin文件含义，需要搞明白<code>database.db</code>内有什么东西，它是feature
extraction的产物。db文件可以用vscode的插件打开，它包含7个table：</p>
<figure>
<img src="/2025/01/09/Novel-view-synthesis-NVS/image-20250115133036561.png" alt="image-20250115133036561">
<figcaption aria-hidden="true">image-20250115133036561</figcaption>
</figure>
<p>keypoints表格中，我下图截图的data部分里才是所有feature的信息，内有每一个feature所在的X，Y坐标。</p>
<blockquote>
<p>COLMAP uses the convention that the upper left image corner has
coordinate (0, 0) and the center of the upper left most pixel has
coordinate (0.5, 0.5)</p>
<p>COLMAP在表示图像坐标时，采用了一种特定的坐标系统，其中图像的左上角被定义为坐标原点
(0, 0)。而“the center of the upper left most pixel has coordinate (0.5,
0.5)” 指的是图像中最左上角的像素的中心位置被赋予了坐标 (0.5, 0.5)。</p>
</blockquote>
<figure>
<img src="/2025/01/09/Novel-view-synthesis-NVS/image-20250115133949032.png" alt="image-20250115133949032">
<figcaption aria-hidden="true">image-20250115133949032</figcaption>
</figure>
<p>在这两张表格中，rows表示的数值是number of detected features per
image, 如果rows=0, 那么这个image没有feature</p>
<p>在运行命令<code>colmap exhaustive_matcher --database_path ./data/testscene/database.db</code>后，db文件内的matchs这张表会出现值（之前没有），每一行会表示一张图片和另外一张图片的匹配结果，rows的值表示match上特征点的个数。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2024/08/13/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="YAN">
      <meta itemprop="description" content="Be smart! Keep Learning">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="YAN's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/08/13/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/" class="post-title-link" itemprop="url">生成模型</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2024-08-13 14:04:23" itemprop="dateCreated datePublished" datetime="2024-08-13T14:04:23+08:00">2024-08-13</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">Edited on</span>
        <time title="Modified: 2024-12-04 15:30:33" itemprop="dateModified" datetime="2024-12-04T15:30:33+08:00">2024-12-04</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/NLP/" itemprop="url" rel="index"><span itemprop="name">NLP</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="Symbols count in article">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">Symbols count in article: </span>
      <span>2.3k</span>
    </span>
    <span class="post-meta-item" title="Reading time">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">Reading time &asymp;</span>
      <span>2 mins.</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>在这个全民皆Difussion
Model的时代，已经有人忘却了曾经的王者GAN。这篇博客是自己记录学习生成模型，这里的生成模型仅局限于生成图片的模型，不是LLM这一类自然语言生成模型。启发点有两个：
-
在斯坦福cs231n这节课里，GAN这一章节详细讲解了从VAE到GAN的发展脉络，并没有延申到Difussion
Model。Difussion Model的内容放到cs236中去讲了。 - Lilian
Blog曾写过一篇<a target="_blank" rel="noopener" href="https://lilianweng.github.io/posts/2021-07-11-diffusion-models/">What
are Diffusion Models?</a>, 内扩展了两篇介绍: GAN 和 VAE。</p>
<h1 id="self-supervised-learning">Self-supervised Learning</h1>
<p>自监督学习中最出彩的就是对比学习。</p>
<h2 id="contrastive-learning">Contrastive Learning</h2>
<p>参考：</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://lilianweng.github.io/posts/2021-05-31-contrastive/">Contrastive
Representation Learning</a></li>
<li><a target="_blank" rel="noopener" href="https://shairozsohail.medium.com/contrastive-representation-learning-a-comprehensive-guide-part-1-foundations-90c1944dbd1e">Contrastive
Representation Learning — A Comprehensive Guide (part 1,
foundations)</a></li>
</ul>
<blockquote>
<p>The goal of contrastive representation learning is to learn such an
embedding space in which similar sample pairs stay close to each other
while dissimilar ones are far apart.</p>
</blockquote>
<p>对比学习的本质思想是：将positive的sample和negtive的sample距离分割的越远。cs231n中的lecture12发展逻辑捋的很好，是因为需要一个更general的pretext
task:</p>
<p><img src="/2024/08/13/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/image-20240904095209899.png" alt="image-20240904095209899">之前的pretext task都是基于"visual common
sense"，例如预测rotations，画面修复inpainting, 颜色填充colorization等，
造成的问题是"learned representations may not be general"。</p>
<p>在contrastive
learning中有一个loss比较重要：<code>infoNCE</code>，是在<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1807.03748">Representation Learning with
Contrastive Predictive
Coding</a>文章中提到的，这个loss就是为了上面的本质思想量身定制，如何将一个class的sample拉的更近，而不属于一个class的sample拉的更远呢？</p>
<figure>
<img src="/2024/08/13/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/image-20240904133326653-17254280087461.png" alt="image-20240904133326653">
<figcaption aria-hidden="true">image-20240904133326653</figcaption>
</figure>
<p>这里我贴一下<code>chatgpt</code>对于上述公式为什么可以作为损失函数的解释，比我自己组织的语言要好：</p>
<figure>
<img src="/2024/08/13/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/image-20240904133608437-17254281697663.png" alt="image-20240904133551625">
<figcaption aria-hidden="true">image-20240904133551625</figcaption>
</figure>
<p>那么我们有了基本思想和loss函数之后如何训练这个网络呢？<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2002.05709">A Simple Framework for
Contrastive Learning of Visual Representations</a>
这篇文章给我们介绍了一个<code>SimCLR</code>，可以重点阅读一下。文章内给出了算法伪代码：</p>
<figure>
<img src="/2024/08/13/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/image-20240904134006818.png" alt="image-20240904134006818">
<figcaption aria-hidden="true">image-20240904134006818</figcaption>
</figure>
<p>SimCLR也披露了自己的训练代码：https://github.com/google-research/simclr?tab=readme-ov-file</p>
<p>SimCLR属于<strong>Instance contrastive
learning</strong>中的一种，包括he Kaiming团队所出的MOCO以及MOCO
V2，与之相对应的是另外一种contrastive learning: <strong>Sequence
contrastive learning</strong>, 代表为CPC（<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1807.03748">Representation Learning with
Contrastive Predictive Coding</a>）。其实很好理解，如果接触过image
segmentation这个任务的话，会记得在图像分割这个任务里有两种segmentation，一种是instance
segmentation，一种是semantic segmentation。contrastive
learning中的instance对比学习就是如上面图示，猫的图片它是一个class，我们将猫的图片和狗的图片的距离变大，而让猫和猫的图片的”距离“变小。对于sequence对比学习，顾名思义就是加入了序列的影响：</p>
<figure>
<img src="/2024/08/13/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/image-20240904144210318.png" alt="image-20240904144210318">
<figcaption aria-hidden="true">image-20240904144210318</figcaption>
</figure>
<h1 id="generative-modeling">Generative Modeling</h1>
<p>generative
modeling被认为是自监督学习的一种，但他们俩的目的不一样，前者是希望建立一个模型，我们用这个模型可以生成一些diverse和realistic的图片，后者是希望通过自监督的representation
learning去生成图片更好的features，用这些features去帮助下游任务拥有更好的performance。<img src="/2024/08/13/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/image-20241016103604877.png" alt="image-20241016103604877"></p>
<p>强烈建议阅读<a target="_blank" rel="noopener" href="http://arxiv.org/abs/1701.00160">NIPS 2016
Tutorial: Generative Adversarial Networks</a>,
作者将拟合Pmodel的方式分成两种：</p>
<figure>
<img src="/2024/08/13/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/image-20241016103757996.png" alt="image-20241016103757996">
<figcaption aria-hidden="true">image-20241016103757996</figcaption>
</figure>
<p>其中Explicit Density中可以Tractable
density的PixelRNN是我们所熟知的，我对于Tractable
Density的理解就是可以求导并利用梯度下降去一点点降低loss的函数，那么对于FVBN来说，拟合Pmodel的方式就是：一张图片的概率等于所有这张图片上pixel的联合概率<img src="/2024/08/13/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/image-20241016105016392.png" alt="image-20241016105016392"></p>
<p>而近似估算中的VAE则采用的是一种引入潜在变量z的方式来间接的建模数据，导致密度函数不可解，必须采用变分推断等近似方法。那么为什么要引入潜在变量z呢？</p>
<figure>
<img src="/2024/08/13/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/image-20241016111401857.png" alt="image-20241016111401857">
<figcaption aria-hidden="true">image-20241016111401857</figcaption>
</figure>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2024/06/27/RAG%E4%B8%ADPDF%E7%9A%84%E8%A7%A3%E6%9E%90/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="YAN">
      <meta itemprop="description" content="Be smart! Keep Learning">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="YAN's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/06/27/RAG%E4%B8%ADPDF%E7%9A%84%E8%A7%A3%E6%9E%90/" class="post-title-link" itemprop="url">RAG中PDF的解析</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2024-06-27 13:17:26" itemprop="dateCreated datePublished" datetime="2024-06-27T13:17:26+08:00">2024-06-27</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">Edited on</span>
        <time title="Modified: 2024-08-30 09:38:12" itemprop="dateModified" datetime="2024-08-30T09:38:12+08:00">2024-08-30</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/NLP/" itemprop="url" rel="index"><span itemprop="name">NLP</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="Symbols count in article">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">Symbols count in article: </span>
      <span>5.4k</span>
    </span>
    <span class="post-meta-item" title="Reading time">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">Reading time &asymp;</span>
      <span>5 mins.</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>今天新开一篇文章。前段时间一直忙于项目周期中琐碎的事情，没有好好总结和思考技术核心的东西。探索RAG的应用也有一段时间了，市面上的应用也看的不少，很多的应用包括langchain-chatchat，Dify,
都是整体搭建了一个最basic版本的RAG框架，至于很多细节点，并没有提供更精细化的实现，今天要写的这部分：PDF上传到知识库之后如何parse和chunking，直接影响后续retrival的表现，目前还没有很全面的review来总结这部分内容。这里就对我看到的一些技术做一些整理。</p>
<p>解析PDF文档的难点主要在于如何精确地捕捉页面的整体布局，并将包括<code>表格</code>，<code>标题</code>,
段落以及图片在内的内容转译为文档的文字形式。这一过程涉及到多个技术点，布局的检测，图片中文字的抽取，表格中行与列的识别（如何正确将PDF中的表格识别成可用结构化形式表示的表格，也就是能还原出原表格来）。</p>
<p>目前解析PDF文档主要有三种主流方式：</p>
<ol type="1">
<li>基于规则的方法：这种方法根据文档的组织特性来确定每个部分的样式和内容，代表库：<a target="_blank" rel="noopener" href="https://pypi.org/project/pypdf/">pypdf</a>，
这种方法的适用性比较差，很难通过预设的规则覆盖所有PDF的情形。</li>
<li>基于深度学习模型的方法：一个流行的解决方案是结合了物体检测和OCR模型，代表
Chatdoc</li>
<li>基于多模态大模型的方法：通过这种方法可以解析PDF中复杂结构或者提取关键信息</li>
</ol>
<h1 id="基于规则的方法">基于规则的方法</h1>
<p>基于规则的PDF处理库真的太多了，每一次看到一个应用使用的新的PDF解析器，都要重新看看怎么处理的。比如langchain-chatchat用的是pyMuPDF中的fitz包，见<a target="_blank" rel="noopener" href="https://github.com/chatchat-space/Langchain-Chatchat/blob/master/libs/chatchat-server/chatchat/server/file_rag/document_loaders/mypdfloader.py">langchain-chatchat源代码</a>，这一段处理特别粗糙，我贴上来：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> fitz  <span class="comment"># pyMuPDF里面的fitz包，不要与pip install fitz混淆</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">ocr = get_ocr()</span><br><span class="line">doc = fitz.<span class="built_in">open</span>(filepath)</span><br><span class="line">resp = <span class="string">&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">b_unit = tqdm.tqdm(</span><br><span class="line">    total=doc.page_count, desc=<span class="string">&quot;RapidOCRPDFLoader context page index: 0&quot;</span></span><br><span class="line">)</span><br><span class="line"><span class="keyword">for</span> i, page <span class="keyword">in</span> <span class="built_in">enumerate</span>(doc):</span><br><span class="line">    b_unit.set_description(</span><br><span class="line">        <span class="string">&quot;RapidOCRPDFLoader context page index: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(i)</span><br><span class="line">    )</span><br><span class="line">    b_unit.refresh()</span><br><span class="line">    text = page.get_text(<span class="string">&quot;&quot;</span>)</span><br><span class="line">    resp += text + <span class="string">&quot;\n&quot;</span></span><br><span class="line"></span><br><span class="line">    img_list = page.get_image_info(xrefs=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">for</span> img <span class="keyword">in</span> img_list:</span><br><span class="line">        <span class="keyword">if</span> xref := img.get(<span class="string">&quot;xref&quot;</span>):</span><br><span class="line">                bbox = img[<span class="string">&quot;bbox&quot;</span>]</span><br><span class="line">                <span class="comment"># 检查图片尺寸是否超过设定的阈值</span></span><br><span class="line">                <span class="keyword">if</span> (bbox[<span class="number">2</span>] - bbox[<span class="number">0</span>]) / (page.rect.width) &lt; PDF_OCR_THRESHOLD[</span><br><span class="line">                    <span class="number">0</span></span><br><span class="line">                ] <span class="keyword">or</span> (bbox[<span class="number">3</span>] - bbox[<span class="number">1</span>]) / (</span><br><span class="line">                    page.rect.height</span><br><span class="line">                ) &lt; PDF_OCR_THRESHOLD[<span class="number">1</span>]:</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                    pix = fitz.Pixmap(doc, xref)</span><br><span class="line">                    samples = pix.samples</span><br><span class="line">                    <span class="keyword">if</span> <span class="built_in">int</span>(page.rotation) != <span class="number">0</span>:  <span class="comment"># 如果Page有旋转角度，则旋转图片</span></span><br><span class="line">                        img_array = np.frombuffer(</span><br><span class="line">                            pix.samples, dtype=np.uint8</span><br><span class="line">                        ).reshape(pix.height, pix.width, -<span class="number">1</span>)</span><br><span class="line">                        tmp_img = Image.fromarray(img_array)</span><br><span class="line">                        ori_img = cv2.cvtColor(np.array(tmp_img), cv2.COLOR_RGB2BGR)</span><br><span class="line">                        rot_img = rotate_img(img=ori_img, angle=<span class="number">360</span> - page.rotation)</span><br><span class="line">                        img_array = cv2.cvtColor(rot_img, cv2.COLOR_RGB2BGR)</span><br><span class="line">                        <span class="keyword">else</span>:</span><br><span class="line">                            img_array = np.frombuffer(</span><br><span class="line">                                pix.samples, dtype=np.uint8</span><br><span class="line">                            ).reshape(pix.height, pix.width, -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">                            result, _ = ocr(img_array)</span><br><span class="line">                            <span class="keyword">if</span> result:</span><br><span class="line">                                ocr_result = [line[<span class="number">1</span>] <span class="keyword">for</span> line <span class="keyword">in</span> result]</span><br><span class="line">                                resp += <span class="string">&quot;\n&quot;</span>.join(ocr_result)</span><br></pre></td></tr></table></figure>
<p>注意它对PDF中图片的处理，是将某一页中所有的图片存入一个img_list，然后遍历这个list，用ocr算法抠出里面的文字，将这些文字都放到该页text的末尾，很大程度上丧失了图片在PDF中应该表达的语义，不仅如此，我觉得还影响了retrival的performance，加入了噪声。</p>
<p>再来看看<a target="_blank" rel="noopener" href="https://github.com/langgenius/dify/blob/main/api/core/rag/extractor/pdf_extractor.py">Dify</a>怎么处理的：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pypdfium2</span><br><span class="line">    <span class="keyword">with</span> blob.as_bytes_io() <span class="keyword">as</span> file_path:</span><br><span class="line">        pdf_reader = pypdfium2.PdfDocument(file_path, autoclose=<span class="literal">True</span>)</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="keyword">for</span> page_number, page <span class="keyword">in</span> <span class="built_in">enumerate</span>(pdf_reader):</span><br><span class="line">                text_page = page.get_textpage()</span><br><span class="line">                content = text_page.get_text_range()</span><br><span class="line">                text_page.close()</span><br><span class="line">                page.close()</span><br><span class="line">                metadata = &#123;<span class="string">&quot;source&quot;</span>: blob.source, <span class="string">&quot;page&quot;</span>: page_number&#125;</span><br><span class="line">                <span class="keyword">yield</span> Document(page_content=content, metadata=metadata)</span><br><span class="line">                <span class="keyword">finally</span>:</span><br><span class="line">                    pdf_reader.close()</span><br></pre></td></tr></table></figure>
<p>换了一个pypdfium2的库，<strong>图片完全舍弃</strong>。我也去搜了有没有对两者的比较，见<a target="_blank" rel="noopener" href="https://www.reddit.com/r/learnpython/comments/1796l3g/pypdf_or_pymupdf/">pypdf
or pymupdf?</a>，更有作者做了一个repo用于比较各种library的效果：<a target="_blank" rel="noopener" href="https://github.com/py-pdf/benchmarks">传送门</a>。结论是如果单论文本抽取的质量，pypdfium2是第一</p>
<blockquote>
<p>对于RAG中PDF的处理，我觉得最理想的目标应该是，query能够link到PDF中的图片，不仅如此，这张图片也应该作为reference，目前市面上的reference只能link到相应文件的纯文本。远远不够精细，不过做起来确实有点困难，也需要一点耐心。</p>
</blockquote>
<figure>
<img src="/2024/06/27/RAG%E4%B8%ADPDF%E7%9A%84%E8%A7%A3%E6%9E%90/image-20240628100839214.png" alt="image-20240628100839214">
<figcaption aria-hidden="true">image-20240628100839214</figcaption>
</figure>
<p>更多其他工具的比较可参考<a target="_blank" rel="noopener" href="https://ad-publications.cs.uni-freiburg.de/benchmark.pdf">A
Benchmark and Evaluation for Text Extraction from PDF</a></p>
<figure>
<img src="/2024/06/27/RAG%E4%B8%ADPDF%E7%9A%84%E8%A7%A3%E6%9E%90/image-20240628101040870.png" alt="image-20240628101040870">
<figcaption aria-hidden="true">image-20240628101040870</figcaption>
</figure>
<p>基于规则的方法有一个最大的缺点就是：它会将每一行视为由换行符“”分隔的序列，如果那一行确实是以句号为结尾，影响还稍微小一点，但是如果下一行还在表述这句话，语义上就完全断掉了。要知道在chunking的阶段，大部分的做法是以<code>\n</code>作分隔符的。</p>
<h1 id="基于深度学习模型的方法">基于深度学习模型的方法</h1>
<p>这种方法的又是是它能准确识别整个文档的布局，包括表格和段落。它甚至能理解表格内的结构。这意味着解析出来的表格能完整的解析成表格原本的样子。局限性就在于对象检测和OCR的识别两个阶段可能会耗时。这时候可以考虑采用GPU加速或者多进程和多线程的方式进行处理。</p>
<p>这里有几个开源的代表框架：</p>
<ul>
<li>Unstructured：它是langchain官方推荐的方式。在启用infer_table_structure=True的hi_res策略下，表格的识别效果良好。fast策略下表现不佳</li>
<li>Layout-parser：如果需要识别复杂结构的PDF，建议使用最大的模型，虽然可能会稍慢一点</li>
<li><a target="_blank" rel="noopener" href="https://github.com/PaddlePaddle/PaddleOCR/blob/main/ppstructure/README_ch.md">PP-StructureV2</a>：
采用多种模型组合进行文档的分析，性能优于平均水平。这是百度的飞桨出品的文档智能模型。</li>
</ul>
<p>另外有一些闭源付费的工具诸如ChatDoc和LLama Parse,
这些在现实的落地中存在一定阻碍，毕竟调用API是一定会存在数据上传到别人服务器的风险的，如果是处理非敏感数据，付费API可以做考虑。</p>
<p>这里对Unstructured处理PDF做一些探索。</p>
<p><a target="_blank" rel="noopener" href="https://docs.unstructured.io/open-source/core-functionality/partitioning#partition-pdf">Unstructured</a>对PDF的处理首先是对layout进行检测(detectron2模型)，然后使用tesseract实现OCR的功能，用table
transformer处理table。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> unstructured.partition.pdf <span class="keyword">import</span> partition_pdf</span><br><span class="line"><span class="comment"># Get elements</span></span><br><span class="line">raw_pdf_elements = partition_pdf(</span><br><span class="line">    filename=test_file,</span><br><span class="line">    <span class="comment"># Using pdf format to find embedded image blocks</span></span><br><span class="line">    extract_images_in_pdf=<span class="literal">True</span>,</span><br><span class="line">    <span class="comment"># Use layout model (YOLOX) to get bounding boxes (for tables) and find titles</span></span><br><span class="line">    <span class="comment"># Titles are any sub-section of the document</span></span><br><span class="line">    infer_table_structure=<span class="literal">True</span>,</span><br><span class="line">    <span class="comment"># Post processing to aggregate text once we have the title</span></span><br><span class="line">    chunking_strategy=<span class="string">&quot;by_title&quot;</span>,</span><br><span class="line">    <span class="comment"># Chunking params to aggregate text blocks</span></span><br><span class="line">    <span class="comment"># Attempt to create a new chunk 3800 chars</span></span><br><span class="line">    <span class="comment"># Attempt to keep chunks &gt; 2000 chars</span></span><br><span class="line">    <span class="comment"># Hard max on chunks</span></span><br><span class="line">    max_characters=<span class="number">4000</span>,</span><br><span class="line">    new_after_n_chars=<span class="number">3800</span>,</span><br><span class="line">    combine_text_under_n_chars=<span class="number">2000</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">tables = [el <span class="keyword">for</span> el <span class="keyword">in</span> raw_pdf_elements <span class="keyword">if</span> el.category == <span class="string">&#x27;Table&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(tables[<span class="number">0</span>].text)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(tables[<span class="number">0</span>].metadata.text_as_html)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>上述的第二个输出：将表格转化为html格式，如果将其保存为html，它可以在浏览器中打开，打开后还是一个完整的表格。unstructured的好处就在于它保证了一个表格的完整性。官方给出的<a target="_blank" rel="noopener" href="https://colab.research.google.com/drive/1BJYYyrPVe0_9EGyXqeNyzmVZDrCRZwsg">示例代码</a>中就是将每一个element的text去做embedding，对于表格来说就是将表格的text去做embedding。但是我测试了两个例子发现，它把表格的标题以及表格的注解给弄到其他element里去了，这些文本本应该和表格一起，比如下面的表格：</p>
<figure>
<img src="/2024/06/27/RAG%E4%B8%ADPDF%E7%9A%84%E8%A7%A3%E6%9E%90/image-20240628160939056.png" alt="image-20240628160939056">
<figcaption aria-hidden="true">image-20240628160939056</figcaption>
</figure>
<p>它抽取出来的表格element就只包含纯表格那部分，上面关于Table1的介绍都包含在了上面一个element里</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">3.5 Positional Encoding</span><br><span class="line"></span><br><span class="line">Since our model contains no recurrence and no convolution, in order for the model to make use of the order of the sequence, we must inject some information about the relative or absolute position of the</span><br><span class="line"></span><br><span class="line">5</span><br><span class="line"></span><br><span class="line">Table 1: Maximum path lengths, per-layer complexity and minimum number of sequential operations for different layer types. n is the sequence length, d is the representation dimension, k is the kernel size of convolutions and r the size of the neighborhood in restricted self-attention.</span><br><span class="line">--------------------------------- 上面是另一个element的内容</span><br><span class="line">Layer Type Self-Attention Recurrent Convolutional Self-Attention (restricted) Complexity per Layer O(n2 · d) O(n · d2) O(k · n · d2) O(r · n · d) Sequential Maximum Path Length Operations O(1) O(n) O(1) O(1) O(1) O(n) O(logk(n)) O(n/r)</span><br></pre></td></tr></table></figure>
<h1 id="基于多模态大模型的方法">基于多模态大模型的方法</h1>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/17/">17</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">YAN</span>
</div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
      <span>Symbols count total: </span>
    <span title="Symbols count total">210k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span>Reading time total &asymp;</span>
    <span title="Reading time total">3:11</span>
  </span>
</div>

    </div>
  </footer>

  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@next-theme/pjax@0.5.0/pjax.min.js" integrity="sha256-3NkoLDrmHLTYj7csHIZSr0MHAFTXth7Ua/DDt4MRUAg=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script><script src="/js/bookmark.js"></script><script src="/js/pjax.js"></script>

  
<script src="https://cdn.jsdelivr.net/npm/hexo-generator-searchdb@1.4.0/dist/search.js" integrity="sha256-vXZMYLEqsROAXkEw93GGIvaB2ab+QW6w3+1ahD9nXXA=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>



  <script src="/js/third-party/fancybox.js"></script>

  <script src="/js/third-party/pace.js"></script>

  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js","integrity":"sha256-r+3itOMtGGjap0x+10hu6jW/gZCzxHsoKrOd7gyRSGY="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>



</body>
</html>
