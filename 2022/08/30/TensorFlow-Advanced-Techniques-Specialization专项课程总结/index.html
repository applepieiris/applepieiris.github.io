<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.2">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.loli.net/css?family=consolas:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/themes/blue/pace-theme-minimal.css">
  <script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js" integrity="sha256-gqd7YTjg/BtfqWSwsJOvndl0Bxc8gFImLEkXQT8+qj0=" crossorigin="anonymous"></script>

<script class="next-config" data-name="main" type="application/json">{"hostname":"example.com","root":"/","images":"/images","scheme":"Muse","darkmode":false,"version":"8.8.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":false,"bookmark":{"enable":true,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":"disqus","storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>
<meta name="description" content="Course 1: Custom Models,Layers and loss Functions 多输出 multi output 12345678910111213141516171819202122# Define model layers.input_layer &#x3D; Input(shape&#x3D;(len(train.columns),))first_dense &#x3D; Dense(units">
<meta property="og:type" content="article">
<meta property="og:title" content="TensorFlow-Advanced-Techniques-Specialization专项课程总结">
<meta property="og:url" content="http://example.com/2022/08/30/TensorFlow-Advanced-Techniques-Specialization%E4%B8%93%E9%A1%B9%E8%AF%BE%E7%A8%8B%E6%80%BB%E7%BB%93/index.html">
<meta property="og:site_name" content="YAN&#39;s Blog">
<meta property="og:description" content="Course 1: Custom Models,Layers and loss Functions 多输出 multi output 12345678910111213141516171819202122# Define model layers.input_layer &#x3D; Input(shape&#x3D;(len(train.columns),))first_dense &#x3D; Dense(units">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/2022/08/30/TensorFlow-Advanced-Techniques-Specialization%E4%B8%93%E9%A1%B9%E8%AF%BE%E7%A8%8B%E6%80%BB%E7%BB%93/Users/320150117/AppData/Roaming/Typora/typora-user-images/image-20220830150121062.png">
<meta property="og:image" content="https://miro.medium.com/max/1400/1*LOjfqvJ0zDuSSq443Z9SNA.png">
<meta property="og:image" content="http://example.com/2022/08/30/TensorFlow-Advanced-Techniques-Specialization%E4%B8%93%E9%A1%B9%E8%AF%BE%E7%A8%8B%E6%80%BB%E7%BB%93/Users/320150117/AppData/Roaming/Typora/typora-user-images/image-20220913152542940.png">
<meta property="article:published_time" content="2022-08-30T03:40:11.000Z">
<meta property="article:modified_time" content="2022-09-16T02:44:12.459Z">
<meta property="article:author" content="YAN">
<meta property="article:tag" content="cv">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/2022/08/30/TensorFlow-Advanced-Techniques-Specialization%E4%B8%93%E9%A1%B9%E8%AF%BE%E7%A8%8B%E6%80%BB%E7%BB%93/Users/320150117/AppData/Roaming/Typora/typora-user-images/image-20220830150121062.png">


<link rel="canonical" href="http://example.com/2022/08/30/TensorFlow-Advanced-Techniques-Specialization%E4%B8%93%E9%A1%B9%E8%AF%BE%E7%A8%8B%E6%80%BB%E7%BB%93/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"en","comments":true,"permalink":"http://example.com/2022/08/30/TensorFlow-Advanced-Techniques-Specialization%E4%B8%93%E9%A1%B9%E8%AF%BE%E7%A8%8B%E6%80%BB%E7%BB%93/","path":"2022/08/30/TensorFlow-Advanced-Techniques-Specialization专项课程总结/","title":"TensorFlow-Advanced-Techniques-Specialization专项课程总结"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>TensorFlow-Advanced-Techniques-Specialization专项课程总结 | YAN's Blog</title>
  




  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">YAN's Blog</h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li>
        <li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a></li>
        <li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a></li>
        <li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a></li>
        <li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#course-1-custom-modelslayers-and-loss-functions"><span class="nav-number">1.</span> <span class="nav-text">Course 1:
Custom Models,Layers and loss Functions</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%A4%9A%E8%BE%93%E5%87%BA-multi-output"><span class="nav-number">1.1.</span> <span class="nav-text">多输出 multi output</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%87%AA%E5%AE%9A%E4%B9%89loss-function"><span class="nav-number">1.2.</span> <span class="nav-text">自定义loss function</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#custom-layers-%E8%87%AA%E5%AE%9A%E4%B9%89%E5%B1%82"><span class="nav-number">1.3.</span> <span class="nav-text">custom layers 自定义层</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#lambda-layer"><span class="nav-number">1.3.1.</span> <span class="nav-text">lambda layer</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%87%AA%E5%AE%9A%E4%B9%89model"><span class="nav-number">1.4.</span> <span class="nav-text">自定义model</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#callbacks"><span class="nav-number">1.5.</span> <span class="nav-text">callbacks</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8tensorboard"><span class="nav-number">1.5.1.</span> <span class="nav-text">使用tensorboard</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#earlystoppingcsvloggerlearningrateschedulerreducelronplateau"><span class="nav-number">1.5.2.</span> <span class="nav-text">EarlyStopping,CSVLogger,LearningRateScheduler,ReduceLROnPlateau</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%87%AA%E5%AE%9A%E4%B9%89callbacks"><span class="nav-number">1.5.3.</span> <span class="nav-text">自定义callbacks</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#on_traintestpredict_beginself-logsnone"><span class="nav-number">1.5.3.1.</span> <span class="nav-text">on_(train|test|predict)_begin(self, logs&#x3D;None)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#on_traintestpredict_endself-logsnone"><span class="nav-number">1.5.3.2.</span> <span class="nav-text">on_(train|test|predict)_end(self, logs&#x3D;None)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#on_traintestpredict_batch_beginself-batch-logsnone"><span class="nav-number">1.5.3.3.</span> <span class="nav-text">on_(train|test|predict)_batch_begin(self, batch, logs&#x3D;None)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#on_traintestpredict_batch_endself-batch-logsnone"><span class="nav-number">1.5.3.4.</span> <span class="nav-text">on_(train|test|predict)_batch_end(self, batch, logs&#x3D;None)</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#training-specific-methods"><span class="nav-number">1.5.4.</span> <span class="nav-text">Training specific methods</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#on_epoch_beginself-epoch-logsnone"><span class="nav-number">1.5.4.1.</span> <span class="nav-text">on_epoch_begin(self, epoch, logs&#x3D;None)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#on_epoch_endself-epoch-logsnone"><span class="nav-number">1.5.4.2.</span> <span class="nav-text">on_epoch_end(self, epoch, logs&#x3D;None)</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#course-2-custom-and-distributed-training-with-tensorflow"><span class="nav-number">2.</span> <span class="nav-text">Course
2 : Custom and Distributed Training with Tensorflow</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AF%BC%E6%95%B0%E7%9A%84%E8%AE%A1%E7%AE%97"><span class="nav-number">2.1.</span> <span class="nav-text">导数的计算</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%9C%A8fashion-mnist-%E6%95%B0%E6%8D%AE%E9%9B%86%E4%B8%8A%E5%86%99specific%E7%9A%84%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B"><span class="nav-number">2.2.</span> <span class="nav-text">在fashion mnist
数据集上写specific的训练过程</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83"><span class="nav-number">2.3.</span> <span class="nav-text">分布式训练</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#mirrored-strategy"><span class="nav-number">2.3.1.</span> <span class="nav-text">Mirrored strategy</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#course-3-advanced-computer-vision-with-tensorflow"><span class="nav-number">3.</span> <span class="nav-text">Course 3:
Advanced Computer Vision with Tensorflow</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#object-localization"><span class="nav-number">3.1.</span> <span class="nav-text">Object Localization</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#object-detection"><span class="nav-number">3.2.</span> <span class="nav-text">Object Detection</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%A1%A5%E5%85%85%E4%BB%8B%E7%BB%8Dobject-detection"><span class="nav-number">3.2.1.</span> <span class="nav-text">补充介绍object detection</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#image-segmentation"><span class="nav-number">3.3.</span> <span class="nav-text">image segmentation</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8F%AF%E8%A7%A3%E9%87%8A%E6%80%A7"><span class="nav-number">3.4.</span> <span class="nav-text">可解释性</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#course-4-gans"><span class="nav-number">4.</span> <span class="nav-text">Course 4: GANs</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="YAN"
      src="/images/avatar.jpg">
  <p class="site-author-name" itemprop="name">YAN</p>
  <div class="site-description" itemprop="description">Be smart! Keep Learning</div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">51</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">11</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">21</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>



        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

  <a href="https://github.com/applepieiris" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/08/30/TensorFlow-Advanced-Techniques-Specialization%E4%B8%93%E9%A1%B9%E8%AF%BE%E7%A8%8B%E6%80%BB%E7%BB%93/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="YAN">
      <meta itemprop="description" content="Be smart! Keep Learning">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="YAN's Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          TensorFlow-Advanced-Techniques-Specialization专项课程总结
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-08-30 11:40:11" itemprop="dateCreated datePublished" datetime="2022-08-30T11:40:11+08:00">2022-08-30</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">Edited on</span>
        <time title="Modified: 2022-09-16 10:44:12" itemprop="dateModified" datetime="2022-09-16T10:44:12+08:00">2022-09-16</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">深度学习</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="Symbols count in article">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">Symbols count in article: </span>
      <span>22k</span>
    </span>
    <span class="post-meta-item" title="Reading time">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">Reading time &asymp;</span>
      <span>20 mins.</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <h1 id="course-1-custom-modelslayers-and-loss-functions">Course 1:
Custom Models,Layers and loss Functions</h1>
<h2 id="多输出-multi-output">多输出 multi output</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Define model layers.</span></span><br><span class="line">input_layer = Input(shape=(<span class="built_in">len</span>(train.columns),))</span><br><span class="line">first_dense = Dense(units=<span class="number">128</span>, activation=<span class="string">&#x27;relu&#x27;</span>)(input_layer)</span><br><span class="line">second_dense = Dense(units=<span class="number">128</span>, activation=<span class="string">&#x27;relu&#x27;</span>)(first_dense)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Y1 output will be fed directly from the second dense</span></span><br><span class="line">y1_output = Dense(units=<span class="string">&#x27;1&#x27;</span>, name=<span class="string">&#x27;y1_output&#x27;</span>)(second_dense)</span><br><span class="line">third_dense = Dense(units=<span class="string">&#x27;64&#x27;</span>, activation=<span class="string">&#x27;relu&#x27;</span>)(second_dense)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Y2 output will come via the third dense</span></span><br><span class="line">y2_output = Dense(units=<span class="string">&#x27;1&#x27;</span>, name=<span class="string">&#x27;y2_output&#x27;</span>)(third_dense)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Define the model with the input layer and a list of output layers</span></span><br><span class="line">model = Model(inputs=input_layer, outputs=[y1_output, y2_output])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Specify the optimizer, and compile the model with loss functions for both outputs</span></span><br><span class="line">optimizer = tf.keras.optimizers.SGD(learning_rate=<span class="number">0.001</span>)</span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=optimizer,</span><br><span class="line">              loss=&#123;<span class="string">&#x27;y1_output&#x27;</span>: <span class="string">&#x27;mse&#x27;</span>, <span class="string">&#x27;y2_output&#x27;</span>: <span class="string">&#x27;mse&#x27;</span>&#125;,</span><br><span class="line">              metrics=&#123;<span class="string">&#x27;y1_output&#x27;</span>: tf.keras.metrics.RootMeanSquaredError(),</span><br><span class="line">                       <span class="string">&#x27;y2_output&#x27;</span>: tf.keras.metrics.RootMeanSquaredError()&#125;)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>注意在这种多输出的模型架构下，train_y是一个元组set</p>
<h2 id="自定义loss-function">自定义loss function</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">huber_loss</span>(<span class="params">y_true , y_pred</span>):</span> <span class="comment"># y_true在前，y_pred在后</span></span><br><span class="line">    thresold = <span class="number">1</span></span><br><span class="line">    error = y_true - y_pred</span><br><span class="line">    return_type = tf.<span class="built_in">abs</span>(error) &lt;= thresold</span><br><span class="line">    r1 = <span class="number">0.5</span> * tf.square(error)</span><br><span class="line">    r2 = thresold * (tf.<span class="built_in">abs</span>(error) - (<span class="number">0.5</span>*thresold))</span><br><span class="line">    <span class="keyword">return</span> tf.where(return_type , r1 , r2)</span><br><span class="line"></span><br><span class="line">model_huber_loss = tf.keras.models.Model(inputs=<span class="built_in">input</span> , outputs=output_layer)</span><br><span class="line">model_huber_loss.<span class="built_in">compile</span>(optimizer=<span class="string">&quot;sgd&quot;</span> , loss=huber_loss)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>如果loss function有需要传递别的除了y_ture,y_pred参数： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">huber_loss_wrapper</span>(<span class="params">thresold</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">huber_loss</span>(<span class="params">y_true , y_pred</span>):</span></span><br><span class="line">        error = y_true - y_pred</span><br><span class="line">        return_type = tf.<span class="built_in">abs</span>(error) &lt;= thresold</span><br><span class="line">        r1 = <span class="number">0.5</span> * tf.square(error)</span><br><span class="line">        r2 = thresold * (tf.<span class="built_in">abs</span>(error) - (<span class="number">0.5</span>*thresold))</span><br><span class="line">        <span class="keyword">return</span> tf.where(return_type , r1 , r2)</span><br><span class="line">    <span class="keyword">return</span> huber_loss</span><br><span class="line">model_huber_loss_wrapper = tf.keras.models.Model(inputs=<span class="built_in">input</span> , outputs=output_layer)</span><br><span class="line">model_huber_loss_wrapper.<span class="built_in">compile</span>(optimizer=<span class="string">&quot;sgd&quot;</span> , loss=huber_loss_wrapper(thresold=<span class="number">1</span>))</span><br></pre></td></tr></table></figure>
也可以将loss写成tensorflow.keras.losses的继承类： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.layers <span class="keyword">import</span> Dense , Input</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.losses <span class="keyword">import</span> Loss</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Huber</span>(<span class="params">Loss</span>):</span></span><br><span class="line">    thresold = <span class="number">1</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self , thresold</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.thresold = thresold</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span>(<span class="params">self , y_true , y_pred</span>):</span></span><br><span class="line">        error = y_true - y_pred</span><br><span class="line">        return_type = tf.<span class="built_in">abs</span>(error) &lt;= self.thresold</span><br><span class="line">        r1 = <span class="number">0.5</span> * tf.square(error)</span><br><span class="line">        r2 = self.thresold * (tf.<span class="built_in">abs</span>(error) - (<span class="number">0.5</span>*self.thresold))</span><br><span class="line">        <span class="keyword">return</span> tf.where(return_type , r1 , r2)</span><br><span class="line"></span><br><span class="line"><span class="built_in">input</span> = Input(shape=(<span class="number">1</span>,) , name=<span class="string">&quot;input_layer&quot;</span>)</span><br><span class="line">output_layer = Dense(<span class="number">1</span> , name=<span class="string">&quot;output_layer&quot;</span>)(<span class="built_in">input</span>)</span><br><span class="line">model_huber_loss_class = tf.keras.models.Model(inputs=<span class="built_in">input</span> , outputs=output_layer)</span><br><span class="line"></span><br><span class="line">model_huber_loss_class.<span class="built_in">compile</span>(optimizer=<span class="string">&quot;sgd&quot;</span> , loss=Huber(thresold=<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">model_huber_loss_class.fit(xs,ys,epochs=<span class="number">500</span>,verbose=<span class="number">0</span>)</span><br><span class="line">model_huber_loss_class.predict([[<span class="number">10.0</span>]])</span><br><span class="line"></span><br></pre></td></tr></table></figure></p>
<h2 id="custom-layers-自定义层">custom layers 自定义层</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.nn <span class="keyword">import</span> softmax , relu</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyDenseLayerwithActivation</span>(<span class="params">Layer</span>):</span> <span class="comment"># 可以传递units,activation</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self , units = <span class="number">32</span> ,activation = <span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(MyDenseLayerwithActivation , self).__init__()</span><br><span class="line">        self.units = units</span><br><span class="line">        self.activation = activation</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">build</span>(<span class="params">self , input_shape</span>):</span></span><br><span class="line">        w_init = tf.random_normal_initializer()</span><br><span class="line">        b_init = tf.zeros_initializer()</span><br><span class="line"></span><br><span class="line">        self.w = tf.Variable(initial_value=w_init(shape=(input_shape[-<span class="number">1</span>] , self.units) , dtype=<span class="string">&quot;float32&quot;</span>) , trainable=<span class="literal">True</span> , name=<span class="string">&quot;kernal&quot;</span>)</span><br><span class="line">        self.b = tf.Variable(initial_value=b_init(shape=(self.units , ) , dtype=<span class="string">&quot;float32&quot;</span>) , trainable=<span class="literal">True</span> , name=<span class="string">&quot;bias&quot;</span>)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span>(<span class="params">self , inputs</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.activation( tf.matmul(inputs , self.w) + self.b )</span><br><span class="line"></span><br><span class="line">model_simpledense_activation = Sequential([</span><br><span class="line">    Flatten(input_shape=(<span class="number">28</span>,<span class="number">28</span>)),</span><br><span class="line">    MyDenseLayerwithActivation(units = <span class="number">128</span> , activation=relu),</span><br><span class="line">    MyDenseLayerwithActivation(<span class="number">10</span> , activation = softmax)</span><br><span class="line">])</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="lambda-layer">lambda layer</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">model_lambda = tf.keras.models.Sequential([</span><br><span class="line">    tf.keras.layers.Flatten(input_shape=(<span class="number">28</span>,<span class="number">28</span>)),</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">128</span>),</span><br><span class="line">    tf.keras.layers.Lambda(<span class="keyword">lambda</span> x : tf.<span class="built_in">abs</span>(x)),</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">10</span> , activation=<span class="string">&#x27;softmax&#x27;</span>)</span><br><span class="line">])</span><br></pre></td></tr></table></figure>
<h2 id="自定义model">自定义model</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.keras.layers <span class="keyword">import</span> Dense , Input , concatenate</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.models <span class="keyword">import</span> Model</span><br><span class="line"><span class="keyword">from</span> tensorflow.nn <span class="keyword">import</span> relu </span><br><span class="line"><span class="keyword">from</span> tensorflow.python.keras.utils.vis_utils <span class="keyword">import</span> plot_model</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyOwnModel</span>(<span class="params">Model</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,units = <span class="number">30</span> , activation = <span class="string">&quot;relu&quot;</span> , **kwargs</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.hidden1 = Dense(units , activation=activation , name=<span class="string">&quot;hidden1&quot;</span>)</span><br><span class="line">        self.hidden2 = Dense(units , activation=activation , name=<span class="string">&quot;hidden2&quot;</span>)</span><br><span class="line">        self.main_output = Dense(<span class="number">1</span>)</span><br><span class="line">        self.aux_output = Dense(<span class="number">1</span>)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span>(<span class="params">self , inputs</span>):</span></span><br><span class="line">        input_l , input_r = inputs</span><br><span class="line">        hidden1 = self.hidden1(input_r)</span><br><span class="line">        hidden2 = self.hidden2(hidden1)</span><br><span class="line">        concat = concatenate([input_l , hidden2])</span><br><span class="line">        main_output = self.main_output(concat)</span><br><span class="line">        aux_output  = self.aux_output(hidden2)</span><br><span class="line">        <span class="keyword">return</span> main_output , aux_output</span><br><span class="line"></span><br><span class="line">model = MyOwnModel()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="callbacks">callbacks</h2>
<h3 id="使用tensorboard">使用tensorboard</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.keras.callbacks <span class="keyword">import</span> TensorBoard</span><br><span class="line">model = build_model(dense_units=<span class="number">256</span>)</span><br><span class="line">model.<span class="built_in">compile</span>(</span><br><span class="line">    optimizer=<span class="string">&#x27;sgd&#x27;</span>,</span><br><span class="line">    loss=<span class="string">&#x27;sparse_categorical_crossentropy&#x27;</span>, </span><br><span class="line">    metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line">  </span><br><span class="line">logdir = os.path.join(<span class="string">&quot;logs&quot;</span>, datetime.datetime.now().strftime(<span class="string">&quot;%Y%m%d-%H%M%S&quot;</span>))</span><br><span class="line">tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir)</span><br><span class="line"></span><br><span class="line">model.fit(train_batches, </span><br><span class="line">          epochs=<span class="number">10</span>, </span><br><span class="line">          validation_data=validation_batches, </span><br><span class="line">          callbacks=[tensorboard_callback])</span><br></pre></td></tr></table></figure>
<p>模型训练完之后使用<code>tensorboard --logdir logs</code>来查看模型训练过程中的loss和acc
。
上面这种方式不太适合在服务器调试model，一般采取checkpoint的方式以一定的时间间隔保存模型参数。
### 使用ModelCheckpoint</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.keras.callbacks <span class="keyword">import</span> EarlyStopping, LearningRateScheduler, ModelCheckpoint, CSVLogger, ReduceLROnPlateau</span><br><span class="line"></span><br><span class="line">```python</span><br><span class="line"><span class="comment"># method 1:</span></span><br><span class="line">model = build_model(dense_units=<span class="number">256</span>)</span><br><span class="line">model.<span class="built_in">compile</span>(</span><br><span class="line">    optimizer=<span class="string">&#x27;sgd&#x27;</span>,</span><br><span class="line">    loss=<span class="string">&#x27;sparse_categorical_crossentropy&#x27;</span>, </span><br><span class="line">    metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line">  </span><br><span class="line">model.fit(train_batches, </span><br><span class="line">          epochs=<span class="number">5</span>, </span><br><span class="line">          validation_data=validation_batches, </span><br><span class="line">          verbose=<span class="number">2</span>,</span><br><span class="line">          callbacks=[ModelCheckpoint(<span class="string">&#x27;weights.&#123;epoch:02d&#125;-&#123;val_loss:.2f&#125;.h5&#x27;</span>, verbose=<span class="number">1</span>), <span class="comment"># 这样调用会保存多个文件，每个epoch结束时更新文件</span></span><br><span class="line">          ])</span><br><span class="line"></span><br><span class="line"><span class="comment"># method2:</span></span><br><span class="line">model = build_model(dense_units=<span class="number">256</span>)</span><br><span class="line">model.<span class="built_in">compile</span>(</span><br><span class="line">    optimizer=<span class="string">&#x27;sgd&#x27;</span>,</span><br><span class="line">    loss=<span class="string">&#x27;sparse_categorical_crossentropy&#x27;</span>, </span><br><span class="line">    metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line">  </span><br><span class="line">model.fit(train_batches, </span><br><span class="line">          epochs=<span class="number">2</span>, </span><br><span class="line">          validation_data=validation_batches, </span><br><span class="line">          verbose=<span class="number">2</span>,</span><br><span class="line">          callbacks=[ModelCheckpoint(<span class="string">&#x27;./saved_model&#x27;</span>, verbose=<span class="number">1</span>) <span class="comment"># 如果传入的是一个文件夹，会在文件夹内创建多个文件</span></span><br><span class="line">          ])</span><br></pre></td></tr></table></figure>
<h3 id="earlystoppingcsvloggerlearningrateschedulerreducelronplateau">EarlyStopping,CSVLogger,LearningRateScheduler,ReduceLROnPlateau</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#EarlyStopping</span></span><br><span class="line">model = build_model(dense_units=<span class="number">256</span>)</span><br><span class="line">model.<span class="built_in">compile</span>(</span><br><span class="line">    optimizer=<span class="string">&#x27;sgd&#x27;</span>,</span><br><span class="line">    loss=<span class="string">&#x27;sparse_categorical_crossentropy&#x27;</span>, </span><br><span class="line">    metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line">  </span><br><span class="line">model.fit(train_batches, </span><br><span class="line">          epochs=<span class="number">50</span>, </span><br><span class="line">          validation_data=validation_batches, </span><br><span class="line">          verbose=<span class="number">2</span>,</span><br><span class="line">          callbacks=[EarlyStopping(</span><br><span class="line">              patience=<span class="number">3</span>,</span><br><span class="line">              min_delta=<span class="number">0.05</span>,</span><br><span class="line">              baseline=<span class="number">0.8</span>,</span><br><span class="line">              mode=<span class="string">&#x27;min&#x27;</span>,</span><br><span class="line">              monitor=<span class="string">&#x27;val_loss&#x27;</span>,</span><br><span class="line">              restore_best_weights=<span class="literal">True</span>,</span><br><span class="line">              verbose=<span class="number">1</span>)</span><br><span class="line">          ])</span><br><span class="line"></span><br><span class="line"><span class="comment">#CSVLogger</span></span><br><span class="line">model = build_model(dense_units=<span class="number">256</span>)</span><br><span class="line">model.<span class="built_in">compile</span>(</span><br><span class="line">    optimizer=<span class="string">&#x27;sgd&#x27;</span>,</span><br><span class="line">    loss=<span class="string">&#x27;sparse_categorical_crossentropy&#x27;</span>, </span><br><span class="line">    metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line">  </span><br><span class="line">csv_file = <span class="string">&#x27;training.csv&#x27;</span></span><br><span class="line"></span><br><span class="line">model.fit(train_batches, </span><br><span class="line">          epochs=<span class="number">5</span>, </span><br><span class="line">          validation_data=validation_batches, </span><br><span class="line">          callbacks=[CSVLogger(csv_file)</span><br><span class="line">          ])</span><br><span class="line"></span><br><span class="line"><span class="comment">#LearningRateScheduler</span></span><br><span class="line">model = build_model(dense_units=<span class="number">256</span>)</span><br><span class="line">model.<span class="built_in">compile</span>(</span><br><span class="line">    optimizer=<span class="string">&#x27;sgd&#x27;</span>,</span><br><span class="line">    loss=<span class="string">&#x27;sparse_categorical_crossentropy&#x27;</span>, </span><br><span class="line">    metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line">  </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">step_decay</span>(<span class="params">epoch</span>):</span></span><br><span class="line">	initial_lr = <span class="number">0.01</span></span><br><span class="line">	drop = <span class="number">0.5</span></span><br><span class="line">	epochs_drop = <span class="number">1</span></span><br><span class="line">	lr = initial_lr * math.<span class="built_in">pow</span>(drop, math.floor((<span class="number">1</span>+epoch)/epochs_drop))</span><br><span class="line">	<span class="keyword">return</span> lr</span><br><span class="line"></span><br><span class="line">model.fit(train_batches, </span><br><span class="line">          epochs=<span class="number">5</span>, </span><br><span class="line">          validation_data=validation_batches, </span><br><span class="line">          callbacks=[LearningRateScheduler(step_decay, verbose=<span class="number">1</span>),</span><br><span class="line">                    TensorBoard(log_dir=<span class="string">&#x27;./log_dir&#x27;</span>)]) <span class="comment"># 以上介绍的callbacks可以传递多个item</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#ReduceLROnPlateau</span></span><br><span class="line">model = build_model(dense_units=<span class="number">256</span>)</span><br><span class="line">model.<span class="built_in">compile</span>(</span><br><span class="line">    optimizer=<span class="string">&#x27;sgd&#x27;</span>,</span><br><span class="line">    loss=<span class="string">&#x27;sparse_categorical_crossentropy&#x27;</span>, </span><br><span class="line">    metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line">  </span><br><span class="line">model.fit(train_batches, </span><br><span class="line">          epochs=<span class="number">50</span>, </span><br><span class="line">          validation_data=validation_batches, </span><br><span class="line">          callbacks=[ReduceLROnPlateau(monitor=<span class="string">&#x27;val_loss&#x27;</span>, </span><br><span class="line">                                       factor=<span class="number">0.2</span>, verbose=<span class="number">1</span>,</span><br><span class="line">                                       patience=<span class="number">1</span>, min_lr=<span class="number">0.001</span>),</span><br><span class="line">                     TensorBoard(log_dir=<span class="string">&#x27;./log_dir&#x27;</span>)])</span><br></pre></td></tr></table></figure>
<h3 id="自定义callbacks">自定义callbacks</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DetectOverfittingCallback</span>(<span class="params">tf.keras.callbacks.Callback</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, threshold=<span class="number">0.7</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(DetectOverfittingCallback, self).__init__()</span><br><span class="line">        self.threshold = threshold</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">on_epoch_end</span>(<span class="params">self, epoch, logs=<span class="literal">None</span></span>):</span></span><br><span class="line">        ratio = logs[<span class="string">&quot;val_loss&quot;</span>] / logs[<span class="string">&quot;loss&quot;</span>]</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Epoch: &#123;&#125;, Val/Train loss ratio: &#123;:.2f&#125;&quot;</span>.<span class="built_in">format</span>(epoch, ratio))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> ratio &gt; self.threshold:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Stopping training...&quot;</span>)</span><br><span class="line">            self.model.stop_training = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">model = get_model()</span><br><span class="line">_ = model.fit(x_train, y_train,</span><br><span class="line">              validation_data=(x_test, y_test),</span><br><span class="line">              batch_size=<span class="number">64</span>,</span><br><span class="line">              epochs=<span class="number">3</span>,</span><br><span class="line">              verbose=<span class="number">0</span>,</span><br><span class="line">              callbacks=[DetectOverfittingCallback()])</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>在tf.keras.callbacks.Callback类中还可以重写的函数还有：</p>
<h4 id="on_traintestpredict_beginself-logsnone"><code>on_(train|test|predict)_begin(self, logs=None)</code></h4>
<p>Called at the beginning of
<code>fit</code>/<code>evaluate</code>/<code>predict</code>.</p>
<h4 id="on_traintestpredict_endself-logsnone"><code>on_(train|test|predict)_end(self, logs=None)</code></h4>
<p>Called at the end of
<code>fit</code>/<code>evaluate</code>/<code>predict</code>.</p>
<h4 id="on_traintestpredict_batch_beginself-batch-logsnone"><code>on_(train|test|predict)_batch_begin(self, batch, logs=None)</code></h4>
<p>Called right before processing a batch during
training/testing/predicting. Within this method, <code>logs</code> is a
dict with <code>batch</code> and <code>size</code> available keys,
representing the current batch number and the size of the batch.</p>
<p>logs是一个字典，keys=[batch,size]，分别表示batch number和batch
size</p>
<h4 id="on_traintestpredict_batch_endself-batch-logsnone"><code>on_(train|test|predict)_batch_end(self, batch, logs=None)</code></h4>
<p>Called at the end of training/testing/predicting a batch. Within this
method, <code>logs</code> is a dict containing the stateful metrics
result.</p>
<p>这里的Logs字典中含有metrics结果</p>
<h3 id="training-specific-methods">Training specific methods</h3>
<p>在训练阶段有一些特别的函数：</p>
<h4 id="on_epoch_beginself-epoch-logsnone"><code>on_epoch_begin(self, epoch, logs=None)</code></h4>
<p>Called at the beginning of an epoch during training.</p>
<h4 id="on_epoch_endself-epoch-logsnone"><code>on_epoch_end(self, epoch, logs=None)</code></h4>
<p>Called at the end of an epoch during training.</p>
<p>可以在自定义callback类中定义display结果的函数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Visualization utilities</span></span><br><span class="line">plt.rc(<span class="string">&#x27;font&#x27;</span>, size=<span class="number">20</span>)</span><br><span class="line">plt.rc(<span class="string">&#x27;figure&#x27;</span>, figsize=(<span class="number">15</span>, <span class="number">3</span>))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">display_digits</span>(<span class="params">inputs, outputs, ground_truth, epoch, n=<span class="number">10</span></span>):</span></span><br><span class="line">    plt.clf() <span class="comment"># clear the current figure</span></span><br><span class="line"></span><br><span class="line">    plt.yticks([])</span><br><span class="line">    plt.grid(<span class="literal">None</span>)</span><br><span class="line">    inputs = np.reshape(inputs, [n, <span class="number">28</span>, <span class="number">28</span>])</span><br><span class="line">    inputs = np.swapaxes(inputs, <span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">    inputs = np.reshape(inputs, [<span class="number">28</span>, <span class="number">28</span>*n])</span><br><span class="line">    plt.imshow(inputs)</span><br><span class="line">    plt.xticks([<span class="number">28</span>*x+<span class="number">14</span> <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(n)], outputs)</span><br><span class="line">    <span class="keyword">for</span> i,t <span class="keyword">in</span> <span class="built_in">enumerate</span>(plt.gca().xaxis.get_ticklabels()):</span><br><span class="line">        <span class="keyword">if</span> outputs[i] == ground_truth[i]: </span><br><span class="line">            t.set_color(<span class="string">&#x27;green&#x27;</span>) </span><br><span class="line">        <span class="keyword">else</span>: </span><br><span class="line">            t.set_color(<span class="string">&#x27;red&#x27;</span>)</span><br><span class="line">    plt.grid(<span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line">GIF_PATH = <span class="string">&#x27;./animation.gif&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">VisCallback</span>(<span class="params">tf.keras.callbacks.Callback</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, inputs, ground_truth, display_freq=<span class="number">10</span>, n_samples=<span class="number">10</span></span>):</span></span><br><span class="line">        self.inputs = inputs</span><br><span class="line">        self.ground_truth = ground_truth</span><br><span class="line">        self.images = []</span><br><span class="line">        self.display_freq = display_freq</span><br><span class="line">        self.n_samples = n_samples</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">on_epoch_end</span>(<span class="params">self, epoch, logs=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="comment"># Randomly sample data</span></span><br><span class="line">        indexes = np.random.choice(<span class="built_in">len</span>(self.inputs), size=self.n_samples)</span><br><span class="line">        X_test, y_test = self.inputs[indexes], self.ground_truth[indexes]</span><br><span class="line">        predictions = np.argmax(self.model.predict(X_test), axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Plot the digits</span></span><br><span class="line">        display_digits(X_test, predictions, y_test, epoch, n=self.display_freq)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Save the figure</span></span><br><span class="line">        buf = io.BytesIO()</span><br><span class="line">        plt.savefig(buf, <span class="built_in">format</span>=<span class="string">&#x27;png&#x27;</span>)</span><br><span class="line">        buf.seek(<span class="number">0</span>)</span><br><span class="line">        image = Image.<span class="built_in">open</span>(buf)</span><br><span class="line">        self.images.append(np.array(image))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Display the digits every &#x27;display_freq&#x27; number of epochs</span></span><br><span class="line">        <span class="keyword">if</span> epoch % self.display_freq == <span class="number">0</span>:</span><br><span class="line">            plt.show()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">on_train_end</span>(<span class="params">self, logs=<span class="literal">None</span></span>):</span></span><br><span class="line">        imageio.mimsave(GIF_PATH, self.images, fps=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<h1 id="course-2-custom-and-distributed-training-with-tensorflow">Course
2 : Custom and Distributed Training with Tensorflow</h1>
<h2 id="导数的计算">导数的计算</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">x = tf.Variable(<span class="number">1.0</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape_2:</span><br><span class="line">    <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape_1:</span><br><span class="line">        y = x * x * x</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># The first gradient calculation should occur at leaset</span></span><br><span class="line">    <span class="comment"># within the outer with block</span></span><br><span class="line">    dy_dx = tape_1.gradient(y, x)</span><br><span class="line">d2y_dx2 = tape_2.gradient(dy_dx, x)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(dy_dx)</span><br><span class="line"><span class="built_in">print</span>(d2y_dx2)</span><br></pre></td></tr></table></figure>
<h2 id="在fashion-mnist-数据集上写specific的训练过程">在fashion mnist
数据集上写specific的训练过程</h2>
<p>这种训练方式不采用model.fit()的方式去训练模型，而是采用自己写传递导数的方式。增加了灵活度，方便后续进行分布式训练。</p>
<figure>
<img src="/2022/08/30/TensorFlow-Advanced-Techniques-Specialization%E4%B8%93%E9%A1%B9%E8%AF%BE%E7%A8%8B%E6%80%BB%E7%BB%93/Users\320150117\AppData\Roaming\Typora\typora-user-images\image-20220830150121062.png" alt="image-20220830150121062">
<figcaption aria-hidden="true">image-20220830150121062</figcaption>
</figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.keras.losses <span class="keyword">import</span> SparseCategoricalCrossentropy</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.metrics <span class="keyword">import</span> SparseCategoricalAccuracy</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.optimizers <span class="keyword">import</span> Adam</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">base_model</span>():</span></span><br><span class="line">    <span class="built_in">input</span>  = Input(shape=(<span class="number">28</span>*<span class="number">28</span> , ) , name = <span class="string">&quot;input_layer&quot;</span>)</span><br><span class="line">    x = Dense(<span class="number">64</span> , activation=<span class="string">&#x27;relu&#x27;</span> , name = <span class="string">&quot;dense1&quot;</span>)(<span class="built_in">input</span>)</span><br><span class="line">    x = Dense(<span class="number">64</span> , activation=<span class="string">&#x27;relu&#x27;</span> , name = <span class="string">&quot;dense2&quot;</span>)(x)</span><br><span class="line">    output = Dense(<span class="number">10</span> , activation=<span class="string">&#x27;softmax&#x27;</span> , name=<span class="string">&quot;output_layer&quot;</span>)(x)</span><br><span class="line">    model = Model(inputs = <span class="built_in">input</span> , outputs = output)</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run_optimizer</span>(<span class="params">model , x , y_true</span>):</span></span><br><span class="line">    <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line">        logits = model(x)</span><br><span class="line">        loss_val = loss_obj(y_true=y_true , y_pred=logits)</span><br><span class="line">    grad = tape.gradient(loss_val , model.trainable_weights) <span class="comment"># model有6个可以train的weights</span></span><br><span class="line">    optimizer_obj.apply_gradients(<span class="built_in">zip</span>(grad , model.trainable_weights))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> logits , loss_val</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_one_epoch</span>(<span class="params">model , train_data</span>):</span> <span class="comment"># 这里输入的是整个dataset</span></span><br><span class="line">    losses = []</span><br><span class="line">    pbar = tqdm(total=<span class="built_in">len</span>(<span class="built_in">list</span>(<span class="built_in">enumerate</span>(train_data))), position=<span class="number">0</span>, leave=<span class="literal">True</span>, bar_format=<span class="string">&#x27;&#123;l_bar&#125;&#123;bar&#125;| &#123;n_fmt&#125;/&#123;total_fmt&#125; &#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> batch_no , (data , label) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_data): <span class="comment"># 这个for循环循环的是batch，每次输入模型中训练的是一个batch_size的数据</span></span><br><span class="line">        y_pred , loss = run_optimizer(model , data , label)</span><br><span class="line">        losses.append(loss)</span><br><span class="line">        train_acc_matrix(label , y_pred)</span><br><span class="line">        pbar.set_description(<span class="string">&quot;Training loss for step %s: %.4f&quot;</span> % (<span class="built_in">int</span>(batch_no), <span class="built_in">float</span>(loss)))</span><br><span class="line">        pbar.update()</span><br><span class="line">    <span class="keyword">return</span> losses <span class="comment"># 返回的是一个list，每一个item是一个batch的loss</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">perform_validation</span>(<span class="params">model , test_data</span>):</span></span><br><span class="line">    losses = []</span><br><span class="line">    <span class="keyword">for</span> (data , label) <span class="keyword">in</span> test_data:</span><br><span class="line">        y_pred = model(data)</span><br><span class="line">        loss = loss_obj(label , y_pred)</span><br><span class="line">        losses.append(loss)</span><br><span class="line">        val_acc_matrix(label , y_pred)</span><br><span class="line">    <span class="keyword">return</span> losses</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span>(<span class="params">train , test , epochs = <span class="number">10</span></span>):</span></span><br><span class="line">    model = base_model()</span><br><span class="line"></span><br><span class="line">    history = &#123;&#125;</span><br><span class="line">    history[<span class="string">&#x27;train_loss&#x27;</span>] = []</span><br><span class="line">    history[<span class="string">&#x27;val_loss&#x27;</span>] = []</span><br><span class="line"></span><br><span class="line">    history[<span class="string">&#x27;train_acc&#x27;</span>] = []</span><br><span class="line">    history[<span class="string">&#x27;val_acc&#x27;</span>] = []</span><br><span class="line"></span><br><span class="line">    val_epoch_loss   = []</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Start of epoch %d&#x27;</span> % (epoch,))</span><br><span class="line"></span><br><span class="line">        train_losses = train_one_epoch(model , train_data=train)</span><br><span class="line">        train_acc    = train_acc_matrix.result()</span><br><span class="line">        history[<span class="string">&#x27;train_acc&#x27;</span>].append(train_acc.numpy())</span><br><span class="line">        train_acc_matrix.reset_states()</span><br><span class="line"></span><br><span class="line">        val_losses   = perform_validation(model , test_data=test)</span><br><span class="line">        val_acc      = val_acc_matrix.result()</span><br><span class="line">        history[<span class="string">&#x27;val_acc&#x27;</span>].append(val_acc.numpy())</span><br><span class="line">        val_acc_matrix.reset_states()</span><br><span class="line"></span><br><span class="line">        history[<span class="string">&#x27;train_loss&#x27;</span>].append(np.mean(train_losses)) <span class="comment"># 这里求解的是所有batch的loss总和求平均</span></span><br><span class="line">        history[<span class="string">&#x27;val_loss&#x27;</span>].append(np.mean(val_losses))</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;\n Epoch %s: Train loss: %.4f  Validation Loss: %.4f,\</span></span><br><span class="line"><span class="string">         Train Accuracy: %.4f, Validation Accuracy %.4f&#x27;</span> % (epoch, <span class="built_in">float</span>(np.mean(train_losses)), <span class="built_in">float</span>(np.mean(val_losses)),</span><br><span class="line">                                                            <span class="built_in">float</span>(train_acc), <span class="built_in">float</span>(val_acc)))</span><br><span class="line"></span><br><span class="line">    history[<span class="string">&#x27;model&#x27;</span>] = model</span><br><span class="line">    <span class="keyword">return</span> history</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">loss_obj       = SparseCategoricalCrossentropy()</span><br><span class="line">optimizer_obj  = Adam()</span><br><span class="line"></span><br><span class="line">train_acc_matrix = SparseCategoricalAccuracy()</span><br><span class="line">val_acc_matrix   = SparseCategoricalAccuracy()</span><br><span class="line"></span><br><span class="line">history = train(train_data , test_data)</span><br></pre></td></tr></table></figure>
<h2 id="分布式训练">分布式训练</h2>
<h3 id="mirrored-strategy">Mirrored strategy</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">strategy = tf.distribute.MirroredStrategy() </span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Number of devices: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(strategy.num_replicas_in_sync))</span><br><span class="line"></span><br><span class="line">BATCH_SIZE_PER_REPLICA = <span class="number">64</span></span><br><span class="line"><span class="comment"># Use for Mirrored Strategy</span></span><br><span class="line">BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync</span><br><span class="line"></span><br><span class="line"><span class="comment"># Set up the train and eval data set</span></span><br><span class="line">train_dataset = mnist_train.<span class="built_in">map</span>(scale).cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE)</span><br><span class="line">eval_dataset = mnist_test.<span class="built_in">map</span>(scale).batch(BATCH_SIZE)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Use for Mirrored Strategy -- comment out `with strategy.scope():` and deindent for no strategy</span></span><br><span class="line"><span class="keyword">with</span> strategy.scope():</span><br><span class="line">    model = tf.keras.Sequential([</span><br><span class="line">      tf.keras.layers.Conv2D(<span class="number">32</span>, <span class="number">3</span>, activation=<span class="string">&#x27;relu&#x27;</span>, input_shape=(<span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>)),</span><br><span class="line">      tf.keras.layers.MaxPooling2D(),</span><br><span class="line">      tf.keras.layers.Flatten(),</span><br><span class="line">      tf.keras.layers.Dense(<span class="number">64</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">      tf.keras.layers.Dense(<span class="number">10</span>)</span><br><span class="line">    ])</span><br><span class="line">model.<span class="built_in">compile</span>(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="literal">True</span>),</span><br><span class="line">                optimizer=tf.keras.optimizers.Adam(),</span><br><span class="line">                metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br></pre></td></tr></table></figure>
<p>这种方式会使用该机器的所有gpu,如果想指定使用的GPU可以使用</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">gpus = tf.config.experimental.list_logical_devices(<span class="string">&quot;GPU&quot;</span>)</span><br><span class="line"><span class="comment"># gpus = tf.config.list_physical_devices(&#x27;GPU&#x27;)</span></span><br><span class="line">strategy = tf.distribute.MirroredStrategy([gpu.name <span class="keyword">for</span> gpu <span class="keyword">in</span> gpus])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Running on multiple GPUs &#x27;</span>, [gpu.name <span class="keyword">for</span> gpu <span class="keyword">in</span> gpus])</span><br></pre></td></tr></table></figure>
<h1 id="course-3-advanced-computer-vision-with-tensorflow">Course 3:
Advanced Computer Vision with Tensorflow</h1>
<h2 id="object-localization">Object Localization</h2>
<p>week1介绍了transfer
learning和利用minist手写体数据集做的一个简单的物体定位+分类的模型。object
localization和object
detection的区别在于后者需要识别出image中所有物体的Box并能实现分类，而前者只是需要检测出最主要的那个object并分类。可参考博客https://towardsdatascience.com/object-localization-in-overfeat-5bb2f7328b62。</p>
<figure>
<img src="https://miro.medium.com/max/1400/1*LOjfqvJ0zDuSSq443Z9SNA.png" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<h2 id="object-detection">Object Detection</h2>
<p>如果想要开箱即用的方式，作者介绍了tensorflow的API进行调用：https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2.md。在该object
detection写好的API下有几个可用的utils可以使用：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> object_detection.utils <span class="keyword">import</span> label_map_util</span><br><span class="line"><span class="keyword">from</span> object_detection.utils <span class="keyword">import</span> visualization_utils <span class="keyword">as</span> viz_utils</span><br><span class="line"><span class="keyword">from</span> object_detection.utils <span class="keyword">import</span> ops <span class="keyword">as</span> utils_ops <span class="comment"># 在image segmentation中有使用到mask</span></span><br><span class="line"></span><br><span class="line">PATH_TO_LABELS = <span class="string">&#x27;./models/research/object_detection/data/mscoco_label_map.pbtxt&#x27;</span></span><br><span class="line">category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS) <span class="comment"># category_index是一个字典，key为unique id，values也是一个字典：key是index，value是label_name</span></span><br><span class="line"></span><br><span class="line">viz_utils.visualize_boxes_and_labels_on_image_array(</span><br><span class="line">    image_np_with_detections[<span class="number">0</span>],</span><br><span class="line">    result[<span class="string">&#x27;detection_boxes&#x27;</span>][<span class="number">0</span>],</span><br><span class="line">    (result[<span class="string">&#x27;detection_classes&#x27;</span>][<span class="number">0</span>] + label_id_offset).astype(<span class="built_in">int</span>),</span><br><span class="line">    result[<span class="string">&#x27;detection_scores&#x27;</span>][<span class="number">0</span>],</span><br><span class="line">    category_index,</span><br><span class="line">    use_normalized_coordinates=<span class="literal">True</span></span><br><span class="line">) <span class="comment"># images,boxes,classes,scores</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>另外还介绍了在已有weights上finetune模型的方法。使用的例子是tensorflow官方出的tutorial。https://github.com/tensorflow/models/blob/master/research/object_detection/colab_tutorials/eager_few_shot_od_training_tf2_colab.ipynb</p>
<h3 id="补充介绍object-detection">补充介绍object detection</h3>
<p>这里我又去翻阅了一些review的文章，想了解一下在物体检测领域的其他算法。参考文章
Object Detection With Deep Learning: A Review.</p>
<figure>
<img src="/2022/08/30/TensorFlow-Advanced-Techniques-Specialization%E4%B8%93%E9%A1%B9%E8%AF%BE%E7%A8%8B%E6%80%BB%E7%BB%93/Users\320150117\AppData\Roaming\Typora\typora-user-images\image-20220913152542940.png" alt="image-20220913152542940">
<figcaption aria-hidden="true">image-20220913152542940</figcaption>
</figure>
<p>该文章将物体检测领域的模型分为两个种类，第一类就是以R-CNN为代表的region
proposal方法，第二类就是遵循一个统一的模式，将其看成是一个regression/classification的问题.</p>
<ol type="1">
<li>region proposal</li>
</ol>
<p>R-CNN,
SPP-net(在R-CNN基础上进行了改进)，Fast-RCNN，Faster-RCNN，R-FCN。</p>
<ol type="1">
<li>regression/classification based</li>
</ol>
<p>MultiBox，AttentionNet，G-CNN，yolo，SSD（single shot Multibox
detector）</p>
<h2 id="image-segmentation">image segmentation</h2>
<p>除了FCN-8和Unet。作者还介绍了Mask-RCNN。</p>
<h2 id="可解释性">可解释性</h2>
<p>Class Activation Map : A class activation map is a matrix that shows
what parts of the image the model was paying attention to when deciding
what class to assign the image.</p>
<p><a target="_blank" rel="noopener" href="https://github.com/alexisbcook/ResNetCAM-keras/blob/master/ResNet_CAM.py">代码地址</a></p>
<p><a target="_blank" rel="noopener" href="https://alexisbcook.github.io/2017/global-average-pooling-layers-for-object-localization/#:~:text=to%20avoid%20overfitting.-,Global%20Average%20Pooling,of%20a%20three-dimensional%20tensor.">代码博客</a></p>
<p><a target="_blank" rel="noopener" href="https://towardsdatascience.com/class-activation-mapping-using-transfer-learning-of-resnet50-e8ca7cfd657e">参考博客</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> ast</span><br><span class="line"><span class="keyword">import</span> scipy   </span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> cv2     </span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.applications.resnet50 <span class="keyword">import</span> ResNet50, preprocess_input</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.preprocessing <span class="keyword">import</span> image    </span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.models <span class="keyword">import</span> Model   </span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pretrained_path_to_tensor</span>(<span class="params">img_path</span>):</span></span><br><span class="line">    <span class="comment"># loads RGB image as PIL.Image.Image type</span></span><br><span class="line">    img = image.load_img(img_path, target_size=(<span class="number">224</span>, <span class="number">224</span>))</span><br><span class="line">    <span class="comment"># convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)</span></span><br><span class="line">    x = image.img_to_array(img)</span><br><span class="line">    <span class="comment"># convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor</span></span><br><span class="line">    x = np.expand_dims(x, axis=<span class="number">0</span>)</span><br><span class="line">    <span class="comment"># convert RGB -&gt; BGR, subtract mean ImageNet pixel, and return 4D tensor</span></span><br><span class="line">    <span class="keyword">return</span> preprocess_input(x)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_ResNet</span>():</span></span><br><span class="line">    <span class="comment"># define ResNet50 model</span></span><br><span class="line">    model = ResNet50(weights=<span class="string">&#x27;imagenet&#x27;</span>)</span><br><span class="line">    <span class="comment"># model.summary()</span></span><br><span class="line">    <span class="comment"># get AMP layer weights (2048,1000)</span></span><br><span class="line">    all_amp_layer_weights = model.layers[-<span class="number">1</span>].get_weights()[<span class="number">0</span>] <span class="comment"># 这里get_weights()返回的是一个list,list[0]是kernel matrix,list[1]是bias</span></span><br><span class="line">    <span class="comment"># extract wanted output</span></span><br><span class="line">    ResNet_model = Model(inputs=model.<span class="built_in">input</span>, </span><br><span class="line">        outputs=(model.layers[-<span class="number">4</span>].output, model.layers[-<span class="number">1</span>].output)) </span><br><span class="line">    <span class="keyword">return</span> ResNet_model, all_amp_layer_weights</span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">ResNet_CAM</span>(<span class="params">img_path, model, all_amp_layer_weights</span>):</span></span><br><span class="line">    <span class="comment"># get filtered images from convolutional output + model prediction vector</span></span><br><span class="line">    last_conv_output, pred_vec = model.predict(pretrained_path_to_tensor(img_path))</span><br><span class="line">    <span class="comment"># change dimensions of last convolutional outpu tto 7 x 7 x 2048</span></span><br><span class="line">    last_conv_output = np.squeeze(last_conv_output) </span><br><span class="line">    <span class="comment"># get model&#x27;s prediction (number between 0 and 999, inclusive)</span></span><br><span class="line">    pred = np.argmax(pred_vec)</span><br><span class="line">    <span class="comment"># bilinear upsampling to resize each filtered image to size of original image </span></span><br><span class="line">    mat_for_mult = scipy.ndimage.zoom(last_conv_output, (<span class="number">32</span>, <span class="number">32</span>, <span class="number">1</span>), order=<span class="number">1</span>) <span class="comment"># dim: 224 x 224 x 2048</span></span><br><span class="line">    <span class="comment"># get AMP layer weights</span></span><br><span class="line">    amp_layer_weights = all_amp_layer_weights[:, pred] <span class="comment"># dim: (2048,) </span></span><br><span class="line">    <span class="comment"># get class activation map for object class that is predicted to be in the image</span></span><br><span class="line">    final_output = np.dot(mat_for_mult.reshape((<span class="number">224</span>*<span class="number">224</span>, <span class="number">2048</span>)), amp_layer_weights).reshape(<span class="number">224</span>,<span class="number">224</span>) <span class="comment"># dim: 224 x 224</span></span><br><span class="line">    <span class="comment"># return class activation map</span></span><br><span class="line">    <span class="keyword">return</span> final_output, pred</span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_ResNet_CAM</span>(<span class="params">img_path, ax, model, all_amp_layer_weights</span>):</span></span><br><span class="line">    <span class="comment"># load image, convert BGR --&gt; RGB, resize image to 224 x 224,</span></span><br><span class="line">    im = cv2.resize(cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB), (<span class="number">224</span>, <span class="number">224</span>))</span><br><span class="line">    <span class="comment"># plot image</span></span><br><span class="line">    ax.imshow(im, alpha=<span class="number">0.5</span>)</span><br><span class="line">    <span class="comment"># get class activation map</span></span><br><span class="line">    CAM, pred = ResNet_CAM(img_path, model, all_amp_layer_weights)</span><br><span class="line">    <span class="comment"># plot class activation map</span></span><br><span class="line">    ax.imshow(CAM, cmap=<span class="string">&#x27;jet&#x27;</span>, alpha=<span class="number">0.5</span>)</span><br><span class="line">    <span class="comment"># load the dictionary that identifies each ImageNet category to an index in the prediction vector</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;imagenet1000_clsid_to_human.txt&#x27;</span>) <span class="keyword">as</span> imagenet_classes_file:</span><br><span class="line">        imagenet_classes_dict = ast.literal_eval(imagenet_classes_file.read())</span><br><span class="line">    <span class="comment"># obtain the predicted ImageNet category</span></span><br><span class="line">    ax.set_title(imagenet_classes_dict[pred]) </span><br><span class="line"></span><br><span class="line">ResNet_model, all_amp_layer_weights = get_ResNet()</span><br><span class="line">fig, ax = plt.subplots()</span><br><span class="line">CAM = plot_ResNet_CAM(img_path, ax, ResNet_model, all_amp_layer_weights)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>Saliency Maps：see where the pixels that were most impactful to the
final classification were found.
显示的是哪些pixel会对最终的分类结果造成重大影响。</p>
<p>Grad-CAM Map：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">gradModel = Model(inputs=[model.inputs],outputs[model.get_layer(layer_name).output,model.output])</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line">   <span class="comment"># cast the image tensor to a float-32 data type, pass the</span></span><br><span class="line">   <span class="comment"># forward propagate the image through the gradient model, and grab the loss</span></span><br><span class="line">   <span class="comment"># associated with the specific class index</span></span><br><span class="line">   inputs = tf.cast(img_array, tf.float32)</span><br><span class="line">   (convOutputs, predictions) = gradModel(inputs)</span><br><span class="line">   loss = predictions[:, <span class="number">0</span>]</span><br><span class="line">    </span><br><span class="line"><span class="comment"># use automatic differentiation to compute the gradients</span></span><br><span class="line">grads = tape.gradient(loss, convOutputs)</span><br><span class="line"></span><br><span class="line"><span class="comment"># compute the guided gradients</span></span><br><span class="line">castConvOutputs = tf.cast(convOutputs &gt; <span class="number">0</span>, <span class="string">&quot;float32&quot;</span>)</span><br><span class="line">castGrads = tf.cast(grads &gt; <span class="number">0</span>, <span class="string">&quot;float32&quot;</span>)</span><br><span class="line">guidedGrads = castConvOutputs * castGrads * grads</span><br><span class="line"></span><br><span class="line"><span class="comment"># the convolution and guided gradients have a batch dimension</span></span><br><span class="line"><span class="comment"># (which we don&#x27;t need) so let&#x27;s grab the volume itself and</span></span><br><span class="line"><span class="comment"># discard the batch</span></span><br><span class="line">convOutputs = convOutputs[<span class="number">0</span>]</span><br><span class="line">guidedGrads = guidedGrads[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># compute the average of the gradient values, and using them</span></span><br><span class="line"><span class="comment"># as weights, compute the ponderation of the filters with</span></span><br><span class="line"><span class="comment"># respect to the weights</span></span><br><span class="line">weights = tf.reduce_mean(guidedGrads, axis=(<span class="number">0</span>, <span class="number">1</span>))</span><br><span class="line">cam = tf.reduce_sum(tf.multiply(weights, convOutputs), axis=-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># grab the spatial dimensions of the input image and resize</span></span><br><span class="line"><span class="comment"># the output class activation map to match the input image</span></span><br><span class="line"><span class="comment"># dimensions</span></span><br><span class="line">(w, h) = (img_array.shape[<span class="number">2</span>], img_array.shape[<span class="number">1</span>])</span><br><span class="line">heatmap = cv2.resize(cam.numpy(), (w, h))</span><br><span class="line"></span><br><span class="line"><span class="comment"># normalize the heatmap such that all values lie in the range</span></span><br><span class="line"><span class="comment"># [0, 1], scale the resulting values to the range [0, 255],</span></span><br><span class="line"><span class="comment"># and then convert to an unsigned 8-bit integer</span></span><br><span class="line">numer = heatmap - np.<span class="built_in">min</span>(heatmap)</span><br><span class="line">denom = (heatmap.<span class="built_in">max</span>() - heatmap.<span class="built_in">min</span>()) + eps</span><br><span class="line">heatmap = numer / denom</span><br></pre></td></tr></table></figure>
<h1 id="course-4-gans">Course 4: GANs</h1>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="reward-container">
  <div></div>
  <button>
    Donate
  </button>
  <div class="post-reward">
      <div>
        <img src="/images/wechat_pay.jpg" alt="YAN WeChat Pay">
        <span>WeChat Pay</span>
      </div>

  </div>
</div>

          <div class="post-tags">
              <a href="/tags/cv/" rel="tag"># cv</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2022/08/29/%E5%8D%B7%E7%A7%AF%E5%92%8C%E5%8F%8D%E5%8D%B7%E7%A7%AF%E4%B8%AD%E7%9A%84output-shape%E8%AE%A1%E7%AE%97/" rel="prev" title="卷积和反卷积中的output shape计算">
                  <i class="fa fa-chevron-left"></i> 卷积和反卷积中的output shape计算
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2022/10/12/cv2%E4%B8%ADbitwise-and/" rel="next" title="cv2中bitwise_and()">
                  cv2中bitwise_and() <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">YAN</span>
</div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
      <span>Symbols count total: </span>
    <span title="Symbols count total">228k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span>Reading time total &asymp;</span>
    <span title="Reading time total">3:27</span>
  </span>
</div>

    </div>
  </footer>

  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@next-theme/pjax@0.5.0/pjax.min.js" integrity="sha256-3NkoLDrmHLTYj7csHIZSr0MHAFTXth7Ua/DDt4MRUAg=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script><script src="/js/bookmark.js"></script><script src="/js/pjax.js"></script>

  
<script src="https://cdn.jsdelivr.net/npm/hexo-generator-searchdb@1.4.0/dist/search.js" integrity="sha256-vXZMYLEqsROAXkEw93GGIvaB2ab+QW6w3+1ahD9nXXA=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>



  <script src="/js/third-party/fancybox.js"></script>

  <script src="/js/third-party/pace.js"></script>

  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js","integrity":"sha256-r+3itOMtGGjap0x+10hu6jW/gZCzxHsoKrOd7gyRSGY="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>



</body>
</html>
